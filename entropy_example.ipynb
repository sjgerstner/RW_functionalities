{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7739a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export CUDA_VISIBLE_DEVICES=7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebaf5f0",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d274257",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be47b521",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9e8aa425",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "046046b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_lens import HookedTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31f71ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from entropy.compare import unflattened_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3b6ed857",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuron_choice import neuron_choice\n",
    "from entropy.entropy_intervention import make_hooks\n",
    "from argparse import Namespace\n",
    "from utils import NAME_TO_COMBO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b5f8ec",
   "metadata": {},
   "source": [
    "## Constants that define the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2be82d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "INTERVENTION_TYPE = \"zero_ablation\"\n",
    "METRIC = \"entropy\"\n",
    "NEURON_SUBSET = \"weakening_gate-_post+\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d01bec97",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"intervention_results/allenai/OLMo-7B-0424-hf/dolma-small\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67bbbc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXTREMUM = \"min\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a007a615",
   "metadata": {},
   "source": [
    "## Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71807817",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_data = unflattened_data(DATA_PATH, METRIC, NEURON_SUBSET, INTERVENTION_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "826f0bc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([45734, 1024])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1a9025",
   "metadata": {},
   "source": [
    "## Choosing example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65b11551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(31864857)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmin(diff_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68f6a8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "vi = torch.min(diff_data, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b25adb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vi.indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9766c861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(25)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmin(vi.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db38f889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-10.7500, dtype=torch.float16)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vi.values[25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6572c17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(31118)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vi.indices[25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe3950c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-10.7500, dtype=torch.float16)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_data[31118, 25]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1249f12",
   "metadata": {},
   "source": [
    "Okay, so weakening neurons provoke the biggest decrease of entropy at sequence 31118, position 25. Let us see what the text says:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c5bd11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_dataset = datasets.load_from_disk('neuroscope/datasets/dolma-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dccffce8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask'],\n",
       "    num_rows: 45734\n",
       "})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "15828d1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([50279, 43688,   313,  1797,  4565,    10,   253,  7295,  6138,   247,\n",
       "          5522,   273,  1329,   323, 34598,   285, 27335,  9341,   326,   403,\n",
       "         10305,  5454,   984,   273,   253,   473,  6185,  1406, 12955,    13,\n",
       "           347,   973,   347,   247,   747, 34220, 14117, 11726,  1467,   621,\n",
       "         13629,   313, 24584,    10,  6974,   281,  1329,   643,  9341,    13,\n",
       "          1754,   327,  1980,  5054,   878,    15,   187,  6872, 15849,   588,\n",
       "           320, 11966,   407,  1980,  9061,    15,   187,    38,  3354,  4412,\n",
       "          6456,   310,  4390, 31288, 12925,   285,  1491,   670, 26281,   432,\n",
       "           253,  7295,   285,   588,   452,   271,  2898,  1232,   873,   598,\n",
       "           347,  3517,   347,  1896,    15,   187]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_dataset[31118]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2e75964d",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_input_ids = text_dataset[31118]['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6109dac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('allenai/OLMo-7B-0424-hf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "59324f6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|endoftext|>Yesterday (21 December) the Government announced a package of support for hospitality and leisure businesses that are losing trade because of the Omicron variant, as well as a new discretionary Additional Restrictions Grant (ARG) scheme to support other businesses, based on local economic need.\\nThese schemes will be administered by local authorities.\\nEden District Council is currently awaiting guidance and information about eligibility from the Government and will have an application process set up as soon as possible.\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(text_dataset[31118]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3c095f7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_dataset[31118]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "151a793d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|endoftext|>Yesterday (21 December) the Government announced a package of support for hospitality and leisure businesses that are losing trade because of the'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(my_input_ids[:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "843298ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' O'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(my_input_ids[25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d999d64a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [473, 6185, 1406], 'attention_mask': [1, 1, 1]}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(' Omicron')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0c6b8699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -0.0625,  -0.2441,  -2.4375,  -1.4219,  -0.2852,  -0.4121,   0.0352,\n",
      "         -1.8320,  -1.8574,  -0.7656,  -0.6880,   0.2051,  -0.2881,  -1.3828,\n",
      "         -0.9590,  -6.9531,   0.2861,  -1.7871,  -2.4844,  -1.9062,  -3.3203,\n",
      "         -4.2227,  -3.4648,  -4.3438,  -2.7266, -10.7500,  -9.3359,  -1.5205,\n",
      "         -0.4658,  -0.5234,  -1.0488,  -0.0432,  -1.0781,  -0.7148,  -0.9453,\n",
      "          0.4102,  -1.9238,  -1.4707,  -2.0195,  -0.6436,  -1.0977,  -1.2080,\n",
      "         -2.2520,  -1.6289,  -0.3613,   0.0996,  -1.6465,   0.2539,   0.4902,\n",
      "         -0.7598,  -0.3340,  -1.9570,  -1.7227,   1.8818,  -0.3433,   0.2520,\n",
      "         -1.3320,  -0.0176,  -0.7168,  -1.0020,  -1.8008,  -0.9746,  -0.7549,\n",
      "         -2.1680,  -0.3379,  -0.4785,  -1.1602,  -0.0322,   1.3242,  -6.1289,\n",
      "         -2.2031,  -0.8203,  -1.6133,  -0.1504,   0.2500,  -1.9395,   0.0586,\n",
      "         -1.6250,  -0.1592,  -2.3535,  -3.2656,  -1.1445,  -3.1777,  -1.7031,\n",
      "         -1.8994,  -3.1523,  -2.2051,  -1.5625,  -0.7256,  -0.3848,  -0.1023,\n",
      "         -0.4006,   0.3525,  -1.3369,  -2.1445,  -1.7148,   0.0000],\n",
      "       dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "print(diff_data[31118][:97])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9095ba7",
   "metadata": {},
   "source": [
    "## Running the model on the example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "edcbd90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c710eae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0abda53db2c543f8ba7569b08c03b35f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model allenai/OLMo-7B-0424-hf into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "model = HookedTransformer.from_pretrained('allenai/OLMo-7B-0424-hf', refactor_glu=True, device='cuda:6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "91138163",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits, cache = model.run_with_cache(my_input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "262eeef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 96, 50304])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7692a193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['hook_embed', 'blocks.0.hook_resid_pre', 'blocks.0.ln1.hook_scale', 'blocks.0.ln1.hook_normalized', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k', 'blocks.0.attn.hook_v', 'blocks.0.attn.hook_rot_q', 'blocks.0.attn.hook_rot_k', 'blocks.0.attn.hook_attn_scores', 'blocks.0.attn.hook_pattern', 'blocks.0.attn.hook_z', 'blocks.0.hook_attn_out', 'blocks.0.hook_resid_mid', 'blocks.0.ln2.hook_scale', 'blocks.0.ln2.hook_normalized', 'blocks.0.mlp.hook_pre', 'blocks.0.mlp.hook_pre_linear', 'blocks.0.mlp.hook_post', 'blocks.0.hook_mlp_out', 'blocks.0.hook_resid_post', 'blocks.1.hook_resid_pre', 'blocks.1.ln1.hook_scale', 'blocks.1.ln1.hook_normalized', 'blocks.1.attn.hook_q', 'blocks.1.attn.hook_k', 'blocks.1.attn.hook_v', 'blocks.1.attn.hook_rot_q', 'blocks.1.attn.hook_rot_k', 'blocks.1.attn.hook_attn_scores', 'blocks.1.attn.hook_pattern', 'blocks.1.attn.hook_z', 'blocks.1.hook_attn_out', 'blocks.1.hook_resid_mid', 'blocks.1.ln2.hook_scale', 'blocks.1.ln2.hook_normalized', 'blocks.1.mlp.hook_pre', 'blocks.1.mlp.hook_pre_linear', 'blocks.1.mlp.hook_post', 'blocks.1.hook_mlp_out', 'blocks.1.hook_resid_post', 'blocks.2.hook_resid_pre', 'blocks.2.ln1.hook_scale', 'blocks.2.ln1.hook_normalized', 'blocks.2.attn.hook_q', 'blocks.2.attn.hook_k', 'blocks.2.attn.hook_v', 'blocks.2.attn.hook_rot_q', 'blocks.2.attn.hook_rot_k', 'blocks.2.attn.hook_attn_scores', 'blocks.2.attn.hook_pattern', 'blocks.2.attn.hook_z', 'blocks.2.hook_attn_out', 'blocks.2.hook_resid_mid', 'blocks.2.ln2.hook_scale', 'blocks.2.ln2.hook_normalized', 'blocks.2.mlp.hook_pre', 'blocks.2.mlp.hook_pre_linear', 'blocks.2.mlp.hook_post', 'blocks.2.hook_mlp_out', 'blocks.2.hook_resid_post', 'blocks.3.hook_resid_pre', 'blocks.3.ln1.hook_scale', 'blocks.3.ln1.hook_normalized', 'blocks.3.attn.hook_q', 'blocks.3.attn.hook_k', 'blocks.3.attn.hook_v', 'blocks.3.attn.hook_rot_q', 'blocks.3.attn.hook_rot_k', 'blocks.3.attn.hook_attn_scores', 'blocks.3.attn.hook_pattern', 'blocks.3.attn.hook_z', 'blocks.3.hook_attn_out', 'blocks.3.hook_resid_mid', 'blocks.3.ln2.hook_scale', 'blocks.3.ln2.hook_normalized', 'blocks.3.mlp.hook_pre', 'blocks.3.mlp.hook_pre_linear', 'blocks.3.mlp.hook_post', 'blocks.3.hook_mlp_out', 'blocks.3.hook_resid_post', 'blocks.4.hook_resid_pre', 'blocks.4.ln1.hook_scale', 'blocks.4.ln1.hook_normalized', 'blocks.4.attn.hook_q', 'blocks.4.attn.hook_k', 'blocks.4.attn.hook_v', 'blocks.4.attn.hook_rot_q', 'blocks.4.attn.hook_rot_k', 'blocks.4.attn.hook_attn_scores', 'blocks.4.attn.hook_pattern', 'blocks.4.attn.hook_z', 'blocks.4.hook_attn_out', 'blocks.4.hook_resid_mid', 'blocks.4.ln2.hook_scale', 'blocks.4.ln2.hook_normalized', 'blocks.4.mlp.hook_pre', 'blocks.4.mlp.hook_pre_linear', 'blocks.4.mlp.hook_post', 'blocks.4.hook_mlp_out', 'blocks.4.hook_resid_post', 'blocks.5.hook_resid_pre', 'blocks.5.ln1.hook_scale', 'blocks.5.ln1.hook_normalized', 'blocks.5.attn.hook_q', 'blocks.5.attn.hook_k', 'blocks.5.attn.hook_v', 'blocks.5.attn.hook_rot_q', 'blocks.5.attn.hook_rot_k', 'blocks.5.attn.hook_attn_scores', 'blocks.5.attn.hook_pattern', 'blocks.5.attn.hook_z', 'blocks.5.hook_attn_out', 'blocks.5.hook_resid_mid', 'blocks.5.ln2.hook_scale', 'blocks.5.ln2.hook_normalized', 'blocks.5.mlp.hook_pre', 'blocks.5.mlp.hook_pre_linear', 'blocks.5.mlp.hook_post', 'blocks.5.hook_mlp_out', 'blocks.5.hook_resid_post', 'blocks.6.hook_resid_pre', 'blocks.6.ln1.hook_scale', 'blocks.6.ln1.hook_normalized', 'blocks.6.attn.hook_q', 'blocks.6.attn.hook_k', 'blocks.6.attn.hook_v', 'blocks.6.attn.hook_rot_q', 'blocks.6.attn.hook_rot_k', 'blocks.6.attn.hook_attn_scores', 'blocks.6.attn.hook_pattern', 'blocks.6.attn.hook_z', 'blocks.6.hook_attn_out', 'blocks.6.hook_resid_mid', 'blocks.6.ln2.hook_scale', 'blocks.6.ln2.hook_normalized', 'blocks.6.mlp.hook_pre', 'blocks.6.mlp.hook_pre_linear', 'blocks.6.mlp.hook_post', 'blocks.6.hook_mlp_out', 'blocks.6.hook_resid_post', 'blocks.7.hook_resid_pre', 'blocks.7.ln1.hook_scale', 'blocks.7.ln1.hook_normalized', 'blocks.7.attn.hook_q', 'blocks.7.attn.hook_k', 'blocks.7.attn.hook_v', 'blocks.7.attn.hook_rot_q', 'blocks.7.attn.hook_rot_k', 'blocks.7.attn.hook_attn_scores', 'blocks.7.attn.hook_pattern', 'blocks.7.attn.hook_z', 'blocks.7.hook_attn_out', 'blocks.7.hook_resid_mid', 'blocks.7.ln2.hook_scale', 'blocks.7.ln2.hook_normalized', 'blocks.7.mlp.hook_pre', 'blocks.7.mlp.hook_pre_linear', 'blocks.7.mlp.hook_post', 'blocks.7.hook_mlp_out', 'blocks.7.hook_resid_post', 'blocks.8.hook_resid_pre', 'blocks.8.ln1.hook_scale', 'blocks.8.ln1.hook_normalized', 'blocks.8.attn.hook_q', 'blocks.8.attn.hook_k', 'blocks.8.attn.hook_v', 'blocks.8.attn.hook_rot_q', 'blocks.8.attn.hook_rot_k', 'blocks.8.attn.hook_attn_scores', 'blocks.8.attn.hook_pattern', 'blocks.8.attn.hook_z', 'blocks.8.hook_attn_out', 'blocks.8.hook_resid_mid', 'blocks.8.ln2.hook_scale', 'blocks.8.ln2.hook_normalized', 'blocks.8.mlp.hook_pre', 'blocks.8.mlp.hook_pre_linear', 'blocks.8.mlp.hook_post', 'blocks.8.hook_mlp_out', 'blocks.8.hook_resid_post', 'blocks.9.hook_resid_pre', 'blocks.9.ln1.hook_scale', 'blocks.9.ln1.hook_normalized', 'blocks.9.attn.hook_q', 'blocks.9.attn.hook_k', 'blocks.9.attn.hook_v', 'blocks.9.attn.hook_rot_q', 'blocks.9.attn.hook_rot_k', 'blocks.9.attn.hook_attn_scores', 'blocks.9.attn.hook_pattern', 'blocks.9.attn.hook_z', 'blocks.9.hook_attn_out', 'blocks.9.hook_resid_mid', 'blocks.9.ln2.hook_scale', 'blocks.9.ln2.hook_normalized', 'blocks.9.mlp.hook_pre', 'blocks.9.mlp.hook_pre_linear', 'blocks.9.mlp.hook_post', 'blocks.9.hook_mlp_out', 'blocks.9.hook_resid_post', 'blocks.10.hook_resid_pre', 'blocks.10.ln1.hook_scale', 'blocks.10.ln1.hook_normalized', 'blocks.10.attn.hook_q', 'blocks.10.attn.hook_k', 'blocks.10.attn.hook_v', 'blocks.10.attn.hook_rot_q', 'blocks.10.attn.hook_rot_k', 'blocks.10.attn.hook_attn_scores', 'blocks.10.attn.hook_pattern', 'blocks.10.attn.hook_z', 'blocks.10.hook_attn_out', 'blocks.10.hook_resid_mid', 'blocks.10.ln2.hook_scale', 'blocks.10.ln2.hook_normalized', 'blocks.10.mlp.hook_pre', 'blocks.10.mlp.hook_pre_linear', 'blocks.10.mlp.hook_post', 'blocks.10.hook_mlp_out', 'blocks.10.hook_resid_post', 'blocks.11.hook_resid_pre', 'blocks.11.ln1.hook_scale', 'blocks.11.ln1.hook_normalized', 'blocks.11.attn.hook_q', 'blocks.11.attn.hook_k', 'blocks.11.attn.hook_v', 'blocks.11.attn.hook_rot_q', 'blocks.11.attn.hook_rot_k', 'blocks.11.attn.hook_attn_scores', 'blocks.11.attn.hook_pattern', 'blocks.11.attn.hook_z', 'blocks.11.hook_attn_out', 'blocks.11.hook_resid_mid', 'blocks.11.ln2.hook_scale', 'blocks.11.ln2.hook_normalized', 'blocks.11.mlp.hook_pre', 'blocks.11.mlp.hook_pre_linear', 'blocks.11.mlp.hook_post', 'blocks.11.hook_mlp_out', 'blocks.11.hook_resid_post', 'blocks.12.hook_resid_pre', 'blocks.12.ln1.hook_scale', 'blocks.12.ln1.hook_normalized', 'blocks.12.attn.hook_q', 'blocks.12.attn.hook_k', 'blocks.12.attn.hook_v', 'blocks.12.attn.hook_rot_q', 'blocks.12.attn.hook_rot_k', 'blocks.12.attn.hook_attn_scores', 'blocks.12.attn.hook_pattern', 'blocks.12.attn.hook_z', 'blocks.12.hook_attn_out', 'blocks.12.hook_resid_mid', 'blocks.12.ln2.hook_scale', 'blocks.12.ln2.hook_normalized', 'blocks.12.mlp.hook_pre', 'blocks.12.mlp.hook_pre_linear', 'blocks.12.mlp.hook_post', 'blocks.12.hook_mlp_out', 'blocks.12.hook_resid_post', 'blocks.13.hook_resid_pre', 'blocks.13.ln1.hook_scale', 'blocks.13.ln1.hook_normalized', 'blocks.13.attn.hook_q', 'blocks.13.attn.hook_k', 'blocks.13.attn.hook_v', 'blocks.13.attn.hook_rot_q', 'blocks.13.attn.hook_rot_k', 'blocks.13.attn.hook_attn_scores', 'blocks.13.attn.hook_pattern', 'blocks.13.attn.hook_z', 'blocks.13.hook_attn_out', 'blocks.13.hook_resid_mid', 'blocks.13.ln2.hook_scale', 'blocks.13.ln2.hook_normalized', 'blocks.13.mlp.hook_pre', 'blocks.13.mlp.hook_pre_linear', 'blocks.13.mlp.hook_post', 'blocks.13.hook_mlp_out', 'blocks.13.hook_resid_post', 'blocks.14.hook_resid_pre', 'blocks.14.ln1.hook_scale', 'blocks.14.ln1.hook_normalized', 'blocks.14.attn.hook_q', 'blocks.14.attn.hook_k', 'blocks.14.attn.hook_v', 'blocks.14.attn.hook_rot_q', 'blocks.14.attn.hook_rot_k', 'blocks.14.attn.hook_attn_scores', 'blocks.14.attn.hook_pattern', 'blocks.14.attn.hook_z', 'blocks.14.hook_attn_out', 'blocks.14.hook_resid_mid', 'blocks.14.ln2.hook_scale', 'blocks.14.ln2.hook_normalized', 'blocks.14.mlp.hook_pre', 'blocks.14.mlp.hook_pre_linear', 'blocks.14.mlp.hook_post', 'blocks.14.hook_mlp_out', 'blocks.14.hook_resid_post', 'blocks.15.hook_resid_pre', 'blocks.15.ln1.hook_scale', 'blocks.15.ln1.hook_normalized', 'blocks.15.attn.hook_q', 'blocks.15.attn.hook_k', 'blocks.15.attn.hook_v', 'blocks.15.attn.hook_rot_q', 'blocks.15.attn.hook_rot_k', 'blocks.15.attn.hook_attn_scores', 'blocks.15.attn.hook_pattern', 'blocks.15.attn.hook_z', 'blocks.15.hook_attn_out', 'blocks.15.hook_resid_mid', 'blocks.15.ln2.hook_scale', 'blocks.15.ln2.hook_normalized', 'blocks.15.mlp.hook_pre', 'blocks.15.mlp.hook_pre_linear', 'blocks.15.mlp.hook_post', 'blocks.15.hook_mlp_out', 'blocks.15.hook_resid_post', 'blocks.16.hook_resid_pre', 'blocks.16.ln1.hook_scale', 'blocks.16.ln1.hook_normalized', 'blocks.16.attn.hook_q', 'blocks.16.attn.hook_k', 'blocks.16.attn.hook_v', 'blocks.16.attn.hook_rot_q', 'blocks.16.attn.hook_rot_k', 'blocks.16.attn.hook_attn_scores', 'blocks.16.attn.hook_pattern', 'blocks.16.attn.hook_z', 'blocks.16.hook_attn_out', 'blocks.16.hook_resid_mid', 'blocks.16.ln2.hook_scale', 'blocks.16.ln2.hook_normalized', 'blocks.16.mlp.hook_pre', 'blocks.16.mlp.hook_pre_linear', 'blocks.16.mlp.hook_post', 'blocks.16.hook_mlp_out', 'blocks.16.hook_resid_post', 'blocks.17.hook_resid_pre', 'blocks.17.ln1.hook_scale', 'blocks.17.ln1.hook_normalized', 'blocks.17.attn.hook_q', 'blocks.17.attn.hook_k', 'blocks.17.attn.hook_v', 'blocks.17.attn.hook_rot_q', 'blocks.17.attn.hook_rot_k', 'blocks.17.attn.hook_attn_scores', 'blocks.17.attn.hook_pattern', 'blocks.17.attn.hook_z', 'blocks.17.hook_attn_out', 'blocks.17.hook_resid_mid', 'blocks.17.ln2.hook_scale', 'blocks.17.ln2.hook_normalized', 'blocks.17.mlp.hook_pre', 'blocks.17.mlp.hook_pre_linear', 'blocks.17.mlp.hook_post', 'blocks.17.hook_mlp_out', 'blocks.17.hook_resid_post', 'blocks.18.hook_resid_pre', 'blocks.18.ln1.hook_scale', 'blocks.18.ln1.hook_normalized', 'blocks.18.attn.hook_q', 'blocks.18.attn.hook_k', 'blocks.18.attn.hook_v', 'blocks.18.attn.hook_rot_q', 'blocks.18.attn.hook_rot_k', 'blocks.18.attn.hook_attn_scores', 'blocks.18.attn.hook_pattern', 'blocks.18.attn.hook_z', 'blocks.18.hook_attn_out', 'blocks.18.hook_resid_mid', 'blocks.18.ln2.hook_scale', 'blocks.18.ln2.hook_normalized', 'blocks.18.mlp.hook_pre', 'blocks.18.mlp.hook_pre_linear', 'blocks.18.mlp.hook_post', 'blocks.18.hook_mlp_out', 'blocks.18.hook_resid_post', 'blocks.19.hook_resid_pre', 'blocks.19.ln1.hook_scale', 'blocks.19.ln1.hook_normalized', 'blocks.19.attn.hook_q', 'blocks.19.attn.hook_k', 'blocks.19.attn.hook_v', 'blocks.19.attn.hook_rot_q', 'blocks.19.attn.hook_rot_k', 'blocks.19.attn.hook_attn_scores', 'blocks.19.attn.hook_pattern', 'blocks.19.attn.hook_z', 'blocks.19.hook_attn_out', 'blocks.19.hook_resid_mid', 'blocks.19.ln2.hook_scale', 'blocks.19.ln2.hook_normalized', 'blocks.19.mlp.hook_pre', 'blocks.19.mlp.hook_pre_linear', 'blocks.19.mlp.hook_post', 'blocks.19.hook_mlp_out', 'blocks.19.hook_resid_post', 'blocks.20.hook_resid_pre', 'blocks.20.ln1.hook_scale', 'blocks.20.ln1.hook_normalized', 'blocks.20.attn.hook_q', 'blocks.20.attn.hook_k', 'blocks.20.attn.hook_v', 'blocks.20.attn.hook_rot_q', 'blocks.20.attn.hook_rot_k', 'blocks.20.attn.hook_attn_scores', 'blocks.20.attn.hook_pattern', 'blocks.20.attn.hook_z', 'blocks.20.hook_attn_out', 'blocks.20.hook_resid_mid', 'blocks.20.ln2.hook_scale', 'blocks.20.ln2.hook_normalized', 'blocks.20.mlp.hook_pre', 'blocks.20.mlp.hook_pre_linear', 'blocks.20.mlp.hook_post', 'blocks.20.hook_mlp_out', 'blocks.20.hook_resid_post', 'blocks.21.hook_resid_pre', 'blocks.21.ln1.hook_scale', 'blocks.21.ln1.hook_normalized', 'blocks.21.attn.hook_q', 'blocks.21.attn.hook_k', 'blocks.21.attn.hook_v', 'blocks.21.attn.hook_rot_q', 'blocks.21.attn.hook_rot_k', 'blocks.21.attn.hook_attn_scores', 'blocks.21.attn.hook_pattern', 'blocks.21.attn.hook_z', 'blocks.21.hook_attn_out', 'blocks.21.hook_resid_mid', 'blocks.21.ln2.hook_scale', 'blocks.21.ln2.hook_normalized', 'blocks.21.mlp.hook_pre', 'blocks.21.mlp.hook_pre_linear', 'blocks.21.mlp.hook_post', 'blocks.21.hook_mlp_out', 'blocks.21.hook_resid_post', 'blocks.22.hook_resid_pre', 'blocks.22.ln1.hook_scale', 'blocks.22.ln1.hook_normalized', 'blocks.22.attn.hook_q', 'blocks.22.attn.hook_k', 'blocks.22.attn.hook_v', 'blocks.22.attn.hook_rot_q', 'blocks.22.attn.hook_rot_k', 'blocks.22.attn.hook_attn_scores', 'blocks.22.attn.hook_pattern', 'blocks.22.attn.hook_z', 'blocks.22.hook_attn_out', 'blocks.22.hook_resid_mid', 'blocks.22.ln2.hook_scale', 'blocks.22.ln2.hook_normalized', 'blocks.22.mlp.hook_pre', 'blocks.22.mlp.hook_pre_linear', 'blocks.22.mlp.hook_post', 'blocks.22.hook_mlp_out', 'blocks.22.hook_resid_post', 'blocks.23.hook_resid_pre', 'blocks.23.ln1.hook_scale', 'blocks.23.ln1.hook_normalized', 'blocks.23.attn.hook_q', 'blocks.23.attn.hook_k', 'blocks.23.attn.hook_v', 'blocks.23.attn.hook_rot_q', 'blocks.23.attn.hook_rot_k', 'blocks.23.attn.hook_attn_scores', 'blocks.23.attn.hook_pattern', 'blocks.23.attn.hook_z', 'blocks.23.hook_attn_out', 'blocks.23.hook_resid_mid', 'blocks.23.ln2.hook_scale', 'blocks.23.ln2.hook_normalized', 'blocks.23.mlp.hook_pre', 'blocks.23.mlp.hook_pre_linear', 'blocks.23.mlp.hook_post', 'blocks.23.hook_mlp_out', 'blocks.23.hook_resid_post', 'blocks.24.hook_resid_pre', 'blocks.24.ln1.hook_scale', 'blocks.24.ln1.hook_normalized', 'blocks.24.attn.hook_q', 'blocks.24.attn.hook_k', 'blocks.24.attn.hook_v', 'blocks.24.attn.hook_rot_q', 'blocks.24.attn.hook_rot_k', 'blocks.24.attn.hook_attn_scores', 'blocks.24.attn.hook_pattern', 'blocks.24.attn.hook_z', 'blocks.24.hook_attn_out', 'blocks.24.hook_resid_mid', 'blocks.24.ln2.hook_scale', 'blocks.24.ln2.hook_normalized', 'blocks.24.mlp.hook_pre', 'blocks.24.mlp.hook_pre_linear', 'blocks.24.mlp.hook_post', 'blocks.24.hook_mlp_out', 'blocks.24.hook_resid_post', 'blocks.25.hook_resid_pre', 'blocks.25.ln1.hook_scale', 'blocks.25.ln1.hook_normalized', 'blocks.25.attn.hook_q', 'blocks.25.attn.hook_k', 'blocks.25.attn.hook_v', 'blocks.25.attn.hook_rot_q', 'blocks.25.attn.hook_rot_k', 'blocks.25.attn.hook_attn_scores', 'blocks.25.attn.hook_pattern', 'blocks.25.attn.hook_z', 'blocks.25.hook_attn_out', 'blocks.25.hook_resid_mid', 'blocks.25.ln2.hook_scale', 'blocks.25.ln2.hook_normalized', 'blocks.25.mlp.hook_pre', 'blocks.25.mlp.hook_pre_linear', 'blocks.25.mlp.hook_post', 'blocks.25.hook_mlp_out', 'blocks.25.hook_resid_post', 'blocks.26.hook_resid_pre', 'blocks.26.ln1.hook_scale', 'blocks.26.ln1.hook_normalized', 'blocks.26.attn.hook_q', 'blocks.26.attn.hook_k', 'blocks.26.attn.hook_v', 'blocks.26.attn.hook_rot_q', 'blocks.26.attn.hook_rot_k', 'blocks.26.attn.hook_attn_scores', 'blocks.26.attn.hook_pattern', 'blocks.26.attn.hook_z', 'blocks.26.hook_attn_out', 'blocks.26.hook_resid_mid', 'blocks.26.ln2.hook_scale', 'blocks.26.ln2.hook_normalized', 'blocks.26.mlp.hook_pre', 'blocks.26.mlp.hook_pre_linear', 'blocks.26.mlp.hook_post', 'blocks.26.hook_mlp_out', 'blocks.26.hook_resid_post', 'blocks.27.hook_resid_pre', 'blocks.27.ln1.hook_scale', 'blocks.27.ln1.hook_normalized', 'blocks.27.attn.hook_q', 'blocks.27.attn.hook_k', 'blocks.27.attn.hook_v', 'blocks.27.attn.hook_rot_q', 'blocks.27.attn.hook_rot_k', 'blocks.27.attn.hook_attn_scores', 'blocks.27.attn.hook_pattern', 'blocks.27.attn.hook_z', 'blocks.27.hook_attn_out', 'blocks.27.hook_resid_mid', 'blocks.27.ln2.hook_scale', 'blocks.27.ln2.hook_normalized', 'blocks.27.mlp.hook_pre', 'blocks.27.mlp.hook_pre_linear', 'blocks.27.mlp.hook_post', 'blocks.27.hook_mlp_out', 'blocks.27.hook_resid_post', 'blocks.28.hook_resid_pre', 'blocks.28.ln1.hook_scale', 'blocks.28.ln1.hook_normalized', 'blocks.28.attn.hook_q', 'blocks.28.attn.hook_k', 'blocks.28.attn.hook_v', 'blocks.28.attn.hook_rot_q', 'blocks.28.attn.hook_rot_k', 'blocks.28.attn.hook_attn_scores', 'blocks.28.attn.hook_pattern', 'blocks.28.attn.hook_z', 'blocks.28.hook_attn_out', 'blocks.28.hook_resid_mid', 'blocks.28.ln2.hook_scale', 'blocks.28.ln2.hook_normalized', 'blocks.28.mlp.hook_pre', 'blocks.28.mlp.hook_pre_linear', 'blocks.28.mlp.hook_post', 'blocks.28.hook_mlp_out', 'blocks.28.hook_resid_post', 'blocks.29.hook_resid_pre', 'blocks.29.ln1.hook_scale', 'blocks.29.ln1.hook_normalized', 'blocks.29.attn.hook_q', 'blocks.29.attn.hook_k', 'blocks.29.attn.hook_v', 'blocks.29.attn.hook_rot_q', 'blocks.29.attn.hook_rot_k', 'blocks.29.attn.hook_attn_scores', 'blocks.29.attn.hook_pattern', 'blocks.29.attn.hook_z', 'blocks.29.hook_attn_out', 'blocks.29.hook_resid_mid', 'blocks.29.ln2.hook_scale', 'blocks.29.ln2.hook_normalized', 'blocks.29.mlp.hook_pre', 'blocks.29.mlp.hook_pre_linear', 'blocks.29.mlp.hook_post', 'blocks.29.hook_mlp_out', 'blocks.29.hook_resid_post', 'blocks.30.hook_resid_pre', 'blocks.30.ln1.hook_scale', 'blocks.30.ln1.hook_normalized', 'blocks.30.attn.hook_q', 'blocks.30.attn.hook_k', 'blocks.30.attn.hook_v', 'blocks.30.attn.hook_rot_q', 'blocks.30.attn.hook_rot_k', 'blocks.30.attn.hook_attn_scores', 'blocks.30.attn.hook_pattern', 'blocks.30.attn.hook_z', 'blocks.30.hook_attn_out', 'blocks.30.hook_resid_mid', 'blocks.30.ln2.hook_scale', 'blocks.30.ln2.hook_normalized', 'blocks.30.mlp.hook_pre', 'blocks.30.mlp.hook_pre_linear', 'blocks.30.mlp.hook_post', 'blocks.30.hook_mlp_out', 'blocks.30.hook_resid_post', 'blocks.31.hook_resid_pre', 'blocks.31.ln1.hook_scale', 'blocks.31.ln1.hook_normalized', 'blocks.31.attn.hook_q', 'blocks.31.attn.hook_k', 'blocks.31.attn.hook_v', 'blocks.31.attn.hook_rot_q', 'blocks.31.attn.hook_rot_k', 'blocks.31.attn.hook_attn_scores', 'blocks.31.attn.hook_pattern', 'blocks.31.attn.hook_z', 'blocks.31.hook_attn_out', 'blocks.31.hook_resid_mid', 'blocks.31.ln2.hook_scale', 'blocks.31.ln2.hook_normalized', 'blocks.31.mlp.hook_pre', 'blocks.31.mlp.hook_pre_linear', 'blocks.31.mlp.hook_post', 'blocks.31.hook_mlp_out', 'blocks.31.hook_resid_post', 'ln_final.hook_scale', 'ln_final.hook_normalized'])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cache.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8d78bdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace(\n",
    "    work_dir='.', wcos_dir='.',\n",
    "    model='allenai/OLMo-7B-0424-hf',\n",
    "    neuron_subset_name=\"weakening\",\n",
    "    gate='-', post='+',\n",
    "    activation_location='mlp.hook_post',\n",
    "    intervention_type=INTERVENTION_TYPE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "89f8360b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(tensor(12, device='cuda:0'), tensor(6572, device='cuda:0')), (tensor(17, device='cuda:0'), tensor(8074, device='cuda:0')), (tensor(31, device='cuda:0'), tensor(10867, device='cuda:0')), (tensor(28, device='cuda:0'), tensor(610, device='cuda:0')), (tensor(31, device='cuda:0'), tensor(1043, device='cuda:0')), (tensor(25, device='cuda:0'), tensor(4595, device='cuda:0')), (tensor(30, device='cuda:0'), tensor(4674, device='cuda:0')), (tensor(29, device='cuda:0'), tensor(4984, device='cuda:0')), (tensor(22, device='cuda:0'), tensor(336, device='cuda:0')), (tensor(30, device='cuda:0'), tensor(2463, device='cuda:0')), (tensor(0, device='cuda:0'), tensor(3467, device='cuda:0')), (tensor(18, device='cuda:0'), tensor(1210, device='cuda:0')), (tensor(1, device='cuda:0'), tensor(7896, device='cuda:0')), (tensor(1, device='cuda:0'), tensor(6917, device='cuda:0')), (tensor(26, device='cuda:0'), tensor(5984, device='cuda:0')), (tensor(7, device='cuda:0'), tensor(318, device='cuda:0')), (tensor(12, device='cuda:0'), tensor(6782, device='cuda:0')), (tensor(17, device='cuda:0'), tensor(7388, device='cuda:0')), (tensor(22, device='cuda:0'), tensor(3256, device='cuda:0')), (tensor(31, device='cuda:0'), tensor(10695, device='cuda:0')), (tensor(21, device='cuda:0'), tensor(7064, device='cuda:0')), (tensor(14, device='cuda:0'), tensor(5588, device='cuda:0')), (tensor(28, device='cuda:0'), tensor(3813, device='cuda:0')), (tensor(6, device='cuda:0'), tensor(140, device='cuda:0')), (tensor(4, device='cuda:0'), tensor(7010, device='cuda:0')), (tensor(18, device='cuda:0'), tensor(5807, device='cuda:0')), (tensor(31, device='cuda:0'), tensor(3792, device='cuda:0')), (tensor(14, device='cuda:0'), tensor(3397, device='cuda:0')), (tensor(19, device='cuda:0'), tensor(6282, device='cuda:0')), (tensor(17, device='cuda:0'), tensor(8, device='cuda:0')), (tensor(5, device='cuda:0'), tensor(207, device='cuda:0')), (tensor(26, device='cuda:0'), tensor(78, device='cuda:0')), (tensor(28, device='cuda:0'), tensor(5325, device='cuda:0')), (tensor(26, device='cuda:0'), tensor(5321, device='cuda:0')), (tensor(31, device='cuda:0'), tensor(10690, device='cuda:0')), (tensor(31, device='cuda:0'), tensor(7632, device='cuda:0')), (tensor(31, device='cuda:0'), tensor(5123, device='cuda:0')), (tensor(31, device='cuda:0'), tensor(4099, device='cuda:0')), (tensor(31, device='cuda:0'), tensor(5259, device='cuda:0')), (tensor(31, device='cuda:0'), tensor(3312, device='cuda:0')), (tensor(31, device='cuda:0'), tensor(9693, device='cuda:0')), (tensor(19, device='cuda:0'), tensor(9428, device='cuda:0')), (tensor(26, device='cuda:0'), tensor(4187, device='cuda:0')), (tensor(18, device='cuda:0'), tensor(6799, device='cuda:0')), (tensor(12, device='cuda:0'), tensor(1077, device='cuda:0')), (tensor(29, device='cuda:0'), tensor(7261, device='cuda:0')), (tensor(30, device='cuda:0'), tensor(8784, device='cuda:0')), (tensor(22, device='cuda:0'), tensor(10594, device='cuda:0')), (tensor(3, device='cuda:0'), tensor(221, device='cuda:0')), (tensor(24, device='cuda:0'), tensor(9659, device='cuda:0')), (tensor(21, device='cuda:0'), tensor(7701, device='cuda:0')), (tensor(30, device='cuda:0'), tensor(4767, device='cuda:0')), (tensor(2, device='cuda:0'), tensor(5094, device='cuda:0')), (tensor(31, device='cuda:0'), tensor(10510, device='cuda:0')), (tensor(15, device='cuda:0'), tensor(784, device='cuda:0')), (tensor(31, device='cuda:0'), tensor(5429, device='cuda:0')), (tensor(21, device='cuda:0'), tensor(7071, device='cuda:0')), (tensor(19, device='cuda:0'), tensor(7569, device='cuda:0')), (tensor(31, device='cuda:0'), tensor(3175, device='cuda:0')), (tensor(5, device='cuda:0'), tensor(7685, device='cuda:0')), (tensor(24, device='cuda:0'), tensor(9307, device='cuda:0')), (tensor(26, device='cuda:0'), tensor(8816, device='cuda:0')), (tensor(31, device='cuda:0'), tensor(6436, device='cuda:0')), (tensor(14, device='cuda:0'), tensor(7786, device='cuda:0')), (tensor(29, device='cuda:0'), tensor(5244, device='cuda:0')), (tensor(8, device='cuda:0'), tensor(22, device='cuda:0')), (tensor(26, device='cuda:0'), tensor(5931, device='cuda:0')), (tensor(29, device='cuda:0'), tensor(5237, device='cuda:0')), (tensor(17, device='cuda:0'), tensor(10921, device='cuda:0')), (tensor(17, device='cuda:0'), tensor(1156, device='cuda:0')), (tensor(31, device='cuda:0'), tensor(7764, device='cuda:0')), (tensor(7, device='cuda:0'), tensor(1066, device='cuda:0')), (tensor(12, device='cuda:0'), tensor(7119, device='cuda:0')), (tensor(1, device='cuda:0'), tensor(3985, device='cuda:0')), (tensor(25, device='cuda:0'), tensor(7713, device='cuda:0')), (tensor(23, device='cuda:0'), tensor(5289, device='cuda:0')), (tensor(29, device='cuda:0'), tensor(4412, device='cuda:0')), (tensor(30, device='cuda:0'), tensor(5142, device='cuda:0')), (tensor(30, device='cuda:0'), tensor(6912, device='cuda:0')), (tensor(25, device='cuda:0'), tensor(10213, device='cuda:0')), (tensor(31, device='cuda:0'), tensor(3498, device='cuda:0')), (tensor(31, device='cuda:0'), tensor(6434, device='cuda:0')), (tensor(18, device='cuda:0'), tensor(8088, device='cuda:0')), (tensor(31, device='cuda:0'), tensor(3779, device='cuda:0')), (tensor(31, device='cuda:0'), tensor(9771, device='cuda:0')), (tensor(26, device='cuda:0'), tensor(1672, device='cuda:0')), (tensor(31, device='cuda:0'), tensor(4358, device='cuda:0')), (tensor(31, device='cuda:0'), tensor(6146, device='cuda:0')), (tensor(30, device='cuda:0'), tensor(7167, device='cuda:0')), (tensor(30, device='cuda:0'), tensor(3093, device='cuda:0')), (tensor(18, device='cuda:0'), tensor(3624, device='cuda:0')), (tensor(30, device='cuda:0'), tensor(1508, device='cuda:0')), (tensor(31, device='cuda:0'), tensor(5833, device='cuda:0')), (tensor(31, device='cuda:0'), tensor(4083, device='cuda:0')), (tensor(29, device='cuda:0'), tensor(3281, device='cuda:0')), (tensor(23, device='cuda:0'), tensor(13, device='cuda:0')), (tensor(21, device='cuda:0'), tensor(544, device='cuda:0')), (tensor(31, device='cuda:0'), tensor(9490, device='cuda:0')), (tensor(28, device='cuda:0'), tensor(1676, device='cuda:0')), (tensor(24, device='cuda:0'), tensor(1167, device='cuda:0')), (tensor(30, device='cuda:0'), tensor(10800, device='cuda:0')), (tensor(31, device='cuda:0'), tensor(2607, device='cuda:0')), (tensor(31, device='cuda:0'), tensor(1483, device='cuda:0')), (tensor(18, device='cuda:0'), tensor(4872, device='cuda:0')), (tensor(28, device='cuda:0'), tensor(9376, device='cuda:0')), (tensor(31, device='cuda:0'), tensor(8666, device='cuda:0')), (tensor(2, device='cuda:0'), tensor(3972, device='cuda:0')), (tensor(31, device='cuda:0'), tensor(7228, device='cuda:0')), (tensor(5, device='cuda:0'), tensor(1983, device='cuda:0')), (tensor(4, device='cuda:0'), tensor(304, device='cuda:0')), (tensor(31, device='cuda:0'), tensor(7081, device='cuda:0')), (tensor(25, device='cuda:0'), tensor(3274, device='cuda:0')), (tensor(24, device='cuda:0'), tensor(2931, device='cuda:0')), (tensor(31, device='cuda:0'), tensor(5305, device='cuda:0')), (tensor(31, device='cuda:0'), tensor(8581, device='cuda:0')), (tensor(2, device='cuda:0'), tensor(3807, device='cuda:0')), (tensor(3, device='cuda:0'), tensor(1506, device='cuda:0')), (tensor(11, device='cuda:0'), tensor(9329, device='cuda:0')), (tensor(11, device='cuda:0'), tensor(261, device='cuda:0')), (tensor(31, device='cuda:0'), tensor(2604, device='cuda:0')), (tensor(9, device='cuda:0'), tensor(2861, device='cuda:0')), (tensor(24, device='cuda:0'), tensor(2570, device='cuda:0')), (tensor(30, device='cuda:0'), tensor(9611, device='cuda:0')), (tensor(31, device='cuda:0'), tensor(4192, device='cuda:0')), (tensor(31, device='cuda:0'), tensor(8845, device='cuda:0')), (tensor(1, device='cuda:0'), tensor(10158, device='cuda:0')), (tensor(23, device='cuda:0'), tensor(2134, device='cuda:0')), (tensor(17, device='cuda:0'), tensor(6131, device='cuda:0')), (tensor(29, device='cuda:0'), tensor(881, device='cuda:0')), (tensor(31, device='cuda:0'), tensor(97, device='cuda:0')), (tensor(30, device='cuda:0'), tensor(852, device='cuda:0')), (tensor(27, device='cuda:0'), tensor(5454, device='cuda:0')), (tensor(16, device='cuda:0'), tensor(8880, device='cuda:0')), (tensor(31, device='cuda:0'), tensor(6943, device='cuda:0')), (tensor(31, device='cuda:0'), tensor(8347, device='cuda:0')), (tensor(1, device='cuda:0'), tensor(227, device='cuda:0')), (tensor(20, device='cuda:0'), tensor(387, device='cuda:0')), (tensor(11, device='cuda:0'), tensor(2077, device='cuda:0')), (tensor(7, device='cuda:0'), tensor(8918, device='cuda:0')), (tensor(29, device='cuda:0'), tensor(6527, device='cuda:0')), (tensor(20, device='cuda:0'), tensor(1098, device='cuda:0')), (tensor(30, device='cuda:0'), tensor(9996, device='cuda:0')), (tensor(29, device='cuda:0'), tensor(1895, device='cuda:0')), (tensor(26, device='cuda:0'), tensor(1541, device='cuda:0')), (tensor(19, device='cuda:0'), tensor(8673, device='cuda:0')), (tensor(21, device='cuda:0'), tensor(3495, device='cuda:0')), (tensor(16, device='cuda:0'), tensor(7084, device='cuda:0')), (tensor(1, device='cuda:0'), tensor(1720, device='cuda:0')), (tensor(26, device='cuda:0'), tensor(6841, device='cuda:0')), (tensor(27, device='cuda:0'), tensor(5090, device='cuda:0')), (tensor(31, device='cuda:0'), tensor(5897, device='cuda:0')), (tensor(31, device='cuda:0'), tensor(2008, device='cuda:0')), (tensor(24, device='cuda:0'), tensor(619, device='cuda:0')), (tensor(30, device='cuda:0'), tensor(5045, device='cuda:0')), (tensor(5, device='cuda:0'), tensor(5687, device='cuda:0')), (tensor(18, device='cuda:0'), tensor(4292, device='cuda:0')), (tensor(1, device='cuda:0'), tensor(3983, device='cuda:0')), (tensor(4, device='cuda:0'), tensor(8173, device='cuda:0')), (tensor(29, device='cuda:0'), tensor(555, device='cuda:0')), (tensor(5, device='cuda:0'), tensor(9903, device='cuda:0')), (tensor(14, device='cuda:0'), tensor(4208, device='cuda:0')), (tensor(17, device='cuda:0'), tensor(3826, device='cuda:0')), (tensor(31, device='cuda:0'), tensor(5489, device='cuda:0')), (tensor(26, device='cuda:0'), tensor(4454, device='cuda:0')), (tensor(19, device='cuda:0'), tensor(884, device='cuda:0')), (tensor(24, device='cuda:0'), tensor(67, device='cuda:0')), (tensor(25, device='cuda:0'), tensor(6139, device='cuda:0')), (tensor(31, device='cuda:0'), tensor(1235, device='cuda:0')), (tensor(31, device='cuda:0'), tensor(4568, device='cuda:0')), (tensor(6, device='cuda:0'), tensor(5602, device='cuda:0')), (tensor(25, device='cuda:0'), tensor(782, device='cuda:0')), (tensor(28, device='cuda:0'), tensor(4411, device='cuda:0')), (tensor(31, device='cuda:0'), tensor(5404, device='cuda:0')), (tensor(14, device='cuda:0'), tensor(4816, device='cuda:0')), (tensor(31, device='cuda:0'), tensor(2424, device='cuda:0')), (tensor(29, device='cuda:0'), tensor(700, device='cuda:0')), (tensor(3, device='cuda:0'), tensor(3741, device='cuda:0')), (tensor(27, device='cuda:0'), tensor(589, device='cuda:0')), (tensor(29, device='cuda:0'), tensor(2271, device='cuda:0')), (tensor(1, device='cuda:0'), tensor(10371, device='cuda:0')), (tensor(5, device='cuda:0'), tensor(7619, device='cuda:0')), (tensor(3, device='cuda:0'), tensor(7332, device='cuda:0')), (tensor(30, device='cuda:0'), tensor(3108, device='cuda:0')), (tensor(15, device='cuda:0'), tensor(446, device='cuda:0')), (tensor(31, device='cuda:0'), tensor(3109, device='cuda:0')), (tensor(2, device='cuda:0'), tensor(6609, device='cuda:0')), (tensor(19, device='cuda:0'), tensor(4644, device='cuda:0')), (tensor(25, device='cuda:0'), tensor(9097, device='cuda:0')), (tensor(13, device='cuda:0'), tensor(1847, device='cuda:0')), (tensor(31, device='cuda:0'), tensor(9634, device='cuda:0')), (tensor(0, device='cuda:0'), tensor(365, device='cuda:0')), (tensor(19, device='cuda:0'), tensor(297, device='cuda:0')), (tensor(31, device='cuda:0'), tensor(10917, device='cuda:0')), (tensor(30, device='cuda:0'), tensor(408, device='cuda:0')), (tensor(31, device='cuda:0'), tensor(3693, device='cuda:0')), (tensor(1, device='cuda:0'), tensor(5228, device='cuda:0')), (tensor(20, device='cuda:0'), tensor(1821, device='cuda:0')), (tensor(2, device='cuda:0'), tensor(5267, device='cuda:0')), (tensor(26, device='cuda:0'), tensor(5298, device='cuda:0')), (tensor(28, device='cuda:0'), tensor(5373, device='cuda:0')), (tensor(7, device='cuda:0'), tensor(411, device='cuda:0')), (tensor(31, device='cuda:0'), tensor(3846, device='cuda:0')), (tensor(2, device='cuda:0'), tensor(6148, device='cuda:0')), (tensor(30, device='cuda:0'), tensor(4824, device='cuda:0')), (tensor(26, device='cuda:0'), tensor(391, device='cuda:0')), (tensor(31, device='cuda:0'), tensor(481, device='cuda:0')), (tensor(29, device='cuda:0'), tensor(4131, device='cuda:0')), (tensor(28, device='cuda:0'), tensor(8092, device='cuda:0')), (tensor(30, device='cuda:0'), tensor(6597, device='cuda:0')), (tensor(23, device='cuda:0'), tensor(9611, device='cuda:0')), (tensor(26, device='cuda:0'), tensor(7235, device='cuda:0')), (tensor(31, device='cuda:0'), tensor(8929, device='cuda:0')), (tensor(5, device='cuda:0'), tensor(2990, device='cuda:0')), (tensor(11, device='cuda:0'), tensor(3840, device='cuda:0')), (tensor(31, device='cuda:0'), tensor(1601, device='cuda:0')), (tensor(10, device='cuda:0'), tensor(10026, device='cuda:0')), (tensor(30, device='cuda:0'), tensor(6219, device='cuda:0')), (tensor(23, device='cuda:0'), tensor(10877, device='cuda:0')), (tensor(21, device='cuda:0'), tensor(9907, device='cuda:0')), (tensor(12, device='cuda:0'), tensor(6695, device='cuda:0')), (tensor(26, device='cuda:0'), tensor(6501, device='cuda:0')), (tensor(31, device='cuda:0'), tensor(6870, device='cuda:0')), (tensor(29, device='cuda:0'), tensor(8647, device='cuda:0')), (tensor(26, device='cuda:0'), tensor(202, device='cuda:0')), (tensor(7, device='cuda:0'), tensor(11, device='cuda:0')), (tensor(5, device='cuda:0'), tensor(3511, device='cuda:0')), (tensor(29, device='cuda:0'), tensor(7206, device='cuda:0')), (tensor(11, device='cuda:0'), tensor(1068, device='cuda:0')), (tensor(31, device='cuda:0'), tensor(4087, device='cuda:0')), (tensor(24, device='cuda:0'), tensor(8005, device='cuda:0')), (tensor(30, device='cuda:0'), tensor(3231, device='cuda:0')), (tensor(30, device='cuda:0'), tensor(9325, device='cuda:0')), (tensor(25, device='cuda:0'), tensor(6471, device='cuda:0')), (tensor(31, device='cuda:0'), tensor(1751, device='cuda:0')), (tensor(28, device='cuda:0'), tensor(6431, device='cuda:0')), (tensor(31, device='cuda:0'), tensor(6895, device='cuda:0')), (tensor(1, device='cuda:0'), tensor(2192, device='cuda:0')), (tensor(29, device='cuda:0'), tensor(10374, device='cuda:0')), (tensor(1, device='cuda:0'), tensor(5971, device='cuda:0')), (tensor(15, device='cuda:0'), tensor(6050, device='cuda:0')), (tensor(31, device='cuda:0'), tensor(8839, device='cuda:0')), (tensor(23, device='cuda:0'), tensor(6989, device='cuda:0')), (tensor(22, device='cuda:0'), tensor(8, device='cuda:0'))]\n"
     ]
    }
   ],
   "source": [
    "neuron_list = neuron_choice(\n",
    "            args,\n",
    "            category_key=NAME_TO_COMBO[args.neuron_subset_name],\n",
    "            subset=243,\n",
    "            baseline=False\n",
    "        )\n",
    "print(neuron_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c605ae87",
   "metadata": {},
   "outputs": [],
   "source": [
    "hooks = []\n",
    "conditioning_values = {}\n",
    "for lix, nix in neuron_list:\n",
    "    conditioning_values[(lix,nix)]={}\n",
    "    hooks += make_hooks(\n",
    "        args,\n",
    "        lix, nix,\n",
    "        conditioning_value=conditioning_values[(lix,nix)],\n",
    "        sign=(model.W_gate[lix,:,nix]@model.W_in[lix,:,nix]).item(),\n",
    "        mean_value=0.0,\n",
    "    )\n",
    "#print(hooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4df9c837",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_ablated = model.run_with_hooks(my_input_ids, fwd_hooks=hooks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd780e6c",
   "metadata": {},
   "source": [
    "## Finding relevant tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8cd565d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_diff = logits - logits_ablated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b12554d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 96, 50304])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_diff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "11bb30c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50304])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_logit_diff = logit_diff[0,25,:]\n",
    "relevant_logit_diff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1c41b278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([12.5329,  7.1575,  7.1229,  6.8121,  6.7228,  6.5633,  6.5550,  6.5279,\n",
      "         6.2066,  6.1819,  6.1671,  5.9645,  5.8675,  5.6778,  5.6114,  5.5637],\n",
      "       device='cuda:6', grad_fn=<TopkBackward0>),\n",
      "indices=tensor([ 6185,  6402,  7373, 10929, 34611, 28184, 18227,  8555, 43441,  2494,\n",
      "         4883, 12761, 25810, 36132,  1814, 16192], device='cuda:6'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([-3.3217, -3.2983, -3.2578, -3.1851, -3.1702, -3.1052, -3.1043, -3.0887,\n",
      "        -3.0541, -3.0457, -2.9698, -2.9301, -2.9189, -2.9149, -2.9032, -2.8691],\n",
      "       device='cuda:6', grad_fn=<TopkBackward0>),\n",
      "indices=tensor([12444, 16828,   214,  9676,  5020, 10713,  1972, 22165,   800,  3504,\n",
      "        24761, 13793, 33158,  3153,   731,  1718], device='cuda:6'))\n"
     ]
    }
   ],
   "source": [
    "top = torch.topk(relevant_logit_diff, k=16)\n",
    "bottom = torch.topk(relevant_logit_diff, k=16, largest=False)\n",
    "print(top)\n",
    "print(bottom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0b032f66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mic',\n",
       " 'MI',\n",
       " 'mi',\n",
       " ' Mic',\n",
       " 'MIC',\n",
       " 'Mic',\n",
       " 'micro',\n",
       " ' mic',\n",
       " 'yster',\n",
       " ' micro',\n",
       " 'NS',\n",
       " ' Micro',\n",
       " 'Micro',\n",
       " 'microm',\n",
       " 'mb',\n",
       " 'mn']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to_str_tokens(top.indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e51b38ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '',\n",
       " '',\n",
       " ' illegal',\n",
       " ' majority',\n",
       " ' bulk',\n",
       " 'ances',\n",
       " ' Wayne',\n",
       " 'ative',\n",
       " '',\n",
       " 'houses',\n",
       " '',\n",
       " '\\n\\t\\t\\n\\t',\n",
       " ' live',\n",
       " ' them',\n",
       " ' invest']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to_str_tokens(bottom.indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5cbe5d21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|endoftext|>', ' O', 'mic', 'ron']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to_str_tokens(' Omicron')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a3e1ad",
   "metadata": {},
   "source": [
    "## Ablating weakening neurons generally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "934d8d43",
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 5.38 GiB. GPU 6 has a total capacity of 47.40 GiB of which 2.41 GiB is free. Including non-PyTorch memory, this process has 44.98 GiB memory in use. Of the allocated memory 41.08 GiB is allocated by PyTorch, and 3.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[78]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m lix, nix \u001b[38;5;129;01min\u001b[39;00m neuron_list:\n\u001b[32m      7\u001b[39m     conditioning_values[(lix,nix)]={}\n\u001b[32m      8\u001b[39m     hooks_general += make_hooks(\n\u001b[32m      9\u001b[39m         args,\n\u001b[32m     10\u001b[39m         lix, nix,\n\u001b[32m     11\u001b[39m         conditioning_value=conditioning_values[(lix,nix)],\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m         sign=(model.W_gate[lix,:,nix]\u001b[38;5;129m@model\u001b[39m.W_in[lix,:,nix]).item(),\n\u001b[32m     13\u001b[39m         mean_value=\u001b[32m0.0\u001b[39m,\n\u001b[32m     14\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mounts/work/sgerstner/RW_functionalities/TransformerLens/transformer_lens/HookedTransformer.py:2479\u001b[39m, in \u001b[36mHookedTransformer.W_gate\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2474\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Stack the MLP gate weights across all layers.\u001b[39;00m\n\u001b[32m   2475\u001b[39m \n\u001b[32m   2476\u001b[39m \u001b[33;03mOnly works for models with gated MLPs.\u001b[39;00m\n\u001b[32m   2477\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2478\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cfg.gated_mlp:\n\u001b[32m-> \u001b[39m\u001b[32m2479\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.stack([block.mlp.W_gate \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.blocks], dim=\u001b[32m0\u001b[39m)\n\u001b[32m   2480\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2481\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 5.38 GiB. GPU 6 has a total capacity of 47.40 GiB of which 2.41 GiB is free. Including non-PyTorch memory, this process has 44.98 GiB memory in use. Of the allocated memory 41.08 GiB is allocated by PyTorch, and 3.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "args.gate=None\n",
    "args.post=None\n",
    "\n",
    "hooks_general = []\n",
    "conditioning_values = {}\n",
    "for lix, nix in neuron_list:\n",
    "    conditioning_values[(lix,nix)]={}\n",
    "    hooks_general += make_hooks(\n",
    "        args,\n",
    "        lix, nix,\n",
    "        conditioning_value=conditioning_values[(lix,nix)],\n",
    "        sign=(model.W_gate[lix,:,nix]@model.W_in[lix,:,nix]).item(),\n",
    "        mean_value=0.0,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0711017a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "io2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
