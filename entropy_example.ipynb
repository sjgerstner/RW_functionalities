{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7739a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!export CUDA_VISIBLE_DEVICES=7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebaf5f0",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d274257",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be47b521",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9e8aa425",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "046046b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_lens import HookedTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31f71ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from entropy.compare import unflattened_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b6ed857",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuron_choice import neuron_choice\n",
    "from entropy.entropy_intervention import make_hooks\n",
    "from argparse import Namespace\n",
    "from utils import NAME_TO_COMBO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eefa0e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import neuron_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b5f8ec",
   "metadata": {},
   "source": [
    "## Constants that define the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2be82d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "INTERVENTION_TYPE = \"zero_ablation\"\n",
    "METRIC = \"entropy\"\n",
    "NEURON_SUBSET = \"weakening_gate-_post+\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d01bec97",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"intervention_results/allenai/OLMo-7B-0424-hf/dolma-small\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67bbbc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXTREMUM = \"min\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a007a615",
   "metadata": {},
   "source": [
    "## Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71807817",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_data = unflattened_data(DATA_PATH, METRIC, NEURON_SUBSET, INTERVENTION_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "826f0bc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([45734, 1024])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1a9025",
   "metadata": {},
   "source": [
    "## Choosing example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b11551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(31864857)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#torch.argmin(diff_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68f6a8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "vi = torch.min(diff_data, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b25adb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vi.indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9766c861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(25)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmin(vi.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db38f889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-10.7500, dtype=torch.float16)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vi.values[25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6572c17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(31118)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vi.indices[25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe3950c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-10.7500, dtype=torch.float16)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_data[31118, 25]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1249f12",
   "metadata": {},
   "source": [
    "Okay, so weakening neurons provoke the biggest decrease of entropy at sequence 31118, position 25. Let us see what the text says:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c5bd11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_dataset = datasets.load_from_disk('neuroscope/datasets/dolma-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dccffce8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask'],\n",
       "    num_rows: 45734\n",
       "})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15828d1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([50279, 43688,   313,  1797,  4565,    10,   253,  7295,  6138,   247,\n",
       "          5522,   273,  1329,   323, 34598,   285, 27335,  9341,   326,   403,\n",
       "         10305,  5454,   984,   273,   253,   473,  6185,  1406, 12955,    13,\n",
       "           347,   973,   347,   247,   747, 34220, 14117, 11726,  1467,   621,\n",
       "         13629,   313, 24584,    10,  6974,   281,  1329,   643,  9341,    13,\n",
       "          1754,   327,  1980,  5054,   878,    15,   187,  6872, 15849,   588,\n",
       "           320, 11966,   407,  1980,  9061,    15,   187,    38,  3354,  4412,\n",
       "          6456,   310,  4390, 31288, 12925,   285,  1491,   670, 26281,   432,\n",
       "           253,  7295,   285,   588,   452,   271,  2898,  1232,   873,   598,\n",
       "           347,  3517,   347,  1896,    15,   187]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_dataset[31118]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e75964d",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_input_ids = text_dataset[31118]['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c710eae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f0564e22d7a404894298475e4b68bdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model allenai/OLMo-7B-0424-hf into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "model = HookedTransformer.from_pretrained('allenai/OLMo-7B-0424-hf', refactor_glu=True, device='cuda:6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59324f6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|endoftext|>',\n",
       " 'Yesterday',\n",
       " ' (',\n",
       " '21',\n",
       " ' December',\n",
       " ')',\n",
       " ' the',\n",
       " ' Government',\n",
       " ' announced',\n",
       " ' a',\n",
       " ' package',\n",
       " ' of',\n",
       " ' support',\n",
       " ' for',\n",
       " ' hospitality',\n",
       " ' and',\n",
       " ' leisure',\n",
       " ' businesses',\n",
       " ' that',\n",
       " ' are',\n",
       " ' losing',\n",
       " ' trade',\n",
       " ' because',\n",
       " ' of',\n",
       " ' the',\n",
       " ' O',\n",
       " 'mic',\n",
       " 'ron',\n",
       " ' variant',\n",
       " ',',\n",
       " ' as',\n",
       " ' well',\n",
       " ' as',\n",
       " ' a',\n",
       " ' new',\n",
       " ' discretionary',\n",
       " ' Additional',\n",
       " ' Rest',\n",
       " 'rict',\n",
       " 'ions',\n",
       " ' Grant',\n",
       " ' (',\n",
       " 'ARG',\n",
       " ')',\n",
       " ' scheme',\n",
       " ' to',\n",
       " ' support',\n",
       " ' other',\n",
       " ' businesses',\n",
       " ',',\n",
       " ' based',\n",
       " ' on',\n",
       " ' local',\n",
       " ' economic',\n",
       " ' need',\n",
       " '.',\n",
       " '\\n',\n",
       " 'These',\n",
       " ' schemes',\n",
       " ' will',\n",
       " ' be',\n",
       " ' administered',\n",
       " ' by',\n",
       " ' local',\n",
       " ' authorities',\n",
       " '.',\n",
       " '\\n',\n",
       " 'E',\n",
       " 'den',\n",
       " ' District',\n",
       " ' Council',\n",
       " ' is',\n",
       " ' currently',\n",
       " ' awaiting',\n",
       " ' guidance',\n",
       " ' and',\n",
       " ' information',\n",
       " ' about',\n",
       " ' eligibility',\n",
       " ' from',\n",
       " ' the',\n",
       " ' Government',\n",
       " ' and',\n",
       " ' will',\n",
       " ' have',\n",
       " ' an',\n",
       " ' application',\n",
       " ' process',\n",
       " ' set',\n",
       " ' up',\n",
       " ' as',\n",
       " ' soon',\n",
       " ' as',\n",
       " ' possible',\n",
       " '.',\n",
       " '\\n']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to_str_tokens(text_dataset[31118]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3c095f7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_dataset[31118]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "843298ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mic'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to_single_str_token(my_input_ids[26].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d999d64a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[50279,   473,  6185,  1406]], device='cuda:6')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to_tokens(' Omicron')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c6b8699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -0.0625,  -0.2441,  -2.4375,  -1.4219,  -0.2852,  -0.4121,   0.0352,\n",
      "         -1.8320,  -1.8574,  -0.7656,  -0.6880,   0.2051,  -0.2881,  -1.3828,\n",
      "         -0.9590,  -6.9531,   0.2861,  -1.7871,  -2.4844,  -1.9062,  -3.3203,\n",
      "         -4.2227,  -3.4648,  -4.3438,  -2.7266, -10.7500,  -9.3359,  -1.5205,\n",
      "         -0.4658,  -0.5234,  -1.0488,  -0.0432,  -1.0781,  -0.7148,  -0.9453,\n",
      "          0.4102,  -1.9238,  -1.4707,  -2.0195,  -0.6436,  -1.0977,  -1.2080,\n",
      "         -2.2520,  -1.6289,  -0.3613,   0.0996,  -1.6465,   0.2539,   0.4902,\n",
      "         -0.7598,  -0.3340,  -1.9570,  -1.7227,   1.8818,  -0.3433,   0.2520,\n",
      "         -1.3320,  -0.0176,  -0.7168,  -1.0020,  -1.8008,  -0.9746,  -0.7549,\n",
      "         -2.1680,  -0.3379,  -0.4785,  -1.1602,  -0.0322,   1.3242,  -6.1289,\n",
      "         -2.2031,  -0.8203,  -1.6133,  -0.1504,   0.2500,  -1.9395,   0.0586,\n",
      "         -1.6250,  -0.1592,  -2.3535,  -3.2656,  -1.1445,  -3.1777,  -1.7031,\n",
      "         -1.8994,  -3.1523,  -2.2051,  -1.5625,  -0.7256,  -0.3848,  -0.1023,\n",
      "         -0.4006,   0.3525,  -1.3369,  -2.1445,  -1.7148,   0.0000],\n",
      "       dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "print(diff_data[31118][:97])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcddc567",
   "metadata": {},
   "source": [
    "## List of weakening neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d78bdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace(\n",
    "    work_dir='.', wcos_dir='.',\n",
    "    model='allenai/OLMo-7B-0424-hf',\n",
    "    neuron_subset_name=\"weakening\",\n",
    "    gate='-', post='+',\n",
    "    activation_location='mlp.hook_post',\n",
    "    intervention_type=INTERVENTION_TYPE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "89f8360b",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_list = neuron_choice(\n",
    "            args,\n",
    "            category_key=NAME_TO_COMBO[args.neuron_subset_name],\n",
    "            subset=243,\n",
    "            baseline=False\n",
    "        )\n",
    "#print(neuron_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9095ba7",
   "metadata": {},
   "source": [
    "## Running the model on the example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "91138163",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits, cache = model.run_with_cache(my_input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "262eeef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 96, 50304])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7692a193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['hook_embed', 'blocks.0.hook_resid_pre', 'blocks.0.ln1.hook_scale', 'blocks.0.ln1.hook_normalized', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k', 'blocks.0.attn.hook_v', 'blocks.0.attn.hook_rot_q', 'blocks.0.attn.hook_rot_k', 'blocks.0.attn.hook_attn_scores', 'blocks.0.attn.hook_pattern', 'blocks.0.attn.hook_z', 'blocks.0.hook_attn_out', 'blocks.0.hook_resid_mid', 'blocks.0.ln2.hook_scale', 'blocks.0.ln2.hook_normalized', 'blocks.0.mlp.hook_pre', 'blocks.0.mlp.hook_pre_linear', 'blocks.0.mlp.hook_post', 'blocks.0.hook_mlp_out', 'blocks.0.hook_resid_post', 'blocks.1.hook_resid_pre', 'blocks.1.ln1.hook_scale', 'blocks.1.ln1.hook_normalized', 'blocks.1.attn.hook_q', 'blocks.1.attn.hook_k', 'blocks.1.attn.hook_v', 'blocks.1.attn.hook_rot_q', 'blocks.1.attn.hook_rot_k', 'blocks.1.attn.hook_attn_scores', 'blocks.1.attn.hook_pattern', 'blocks.1.attn.hook_z', 'blocks.1.hook_attn_out', 'blocks.1.hook_resid_mid', 'blocks.1.ln2.hook_scale', 'blocks.1.ln2.hook_normalized', 'blocks.1.mlp.hook_pre', 'blocks.1.mlp.hook_pre_linear', 'blocks.1.mlp.hook_post', 'blocks.1.hook_mlp_out', 'blocks.1.hook_resid_post', 'blocks.2.hook_resid_pre', 'blocks.2.ln1.hook_scale', 'blocks.2.ln1.hook_normalized', 'blocks.2.attn.hook_q', 'blocks.2.attn.hook_k', 'blocks.2.attn.hook_v', 'blocks.2.attn.hook_rot_q', 'blocks.2.attn.hook_rot_k', 'blocks.2.attn.hook_attn_scores', 'blocks.2.attn.hook_pattern', 'blocks.2.attn.hook_z', 'blocks.2.hook_attn_out', 'blocks.2.hook_resid_mid', 'blocks.2.ln2.hook_scale', 'blocks.2.ln2.hook_normalized', 'blocks.2.mlp.hook_pre', 'blocks.2.mlp.hook_pre_linear', 'blocks.2.mlp.hook_post', 'blocks.2.hook_mlp_out', 'blocks.2.hook_resid_post', 'blocks.3.hook_resid_pre', 'blocks.3.ln1.hook_scale', 'blocks.3.ln1.hook_normalized', 'blocks.3.attn.hook_q', 'blocks.3.attn.hook_k', 'blocks.3.attn.hook_v', 'blocks.3.attn.hook_rot_q', 'blocks.3.attn.hook_rot_k', 'blocks.3.attn.hook_attn_scores', 'blocks.3.attn.hook_pattern', 'blocks.3.attn.hook_z', 'blocks.3.hook_attn_out', 'blocks.3.hook_resid_mid', 'blocks.3.ln2.hook_scale', 'blocks.3.ln2.hook_normalized', 'blocks.3.mlp.hook_pre', 'blocks.3.mlp.hook_pre_linear', 'blocks.3.mlp.hook_post', 'blocks.3.hook_mlp_out', 'blocks.3.hook_resid_post', 'blocks.4.hook_resid_pre', 'blocks.4.ln1.hook_scale', 'blocks.4.ln1.hook_normalized', 'blocks.4.attn.hook_q', 'blocks.4.attn.hook_k', 'blocks.4.attn.hook_v', 'blocks.4.attn.hook_rot_q', 'blocks.4.attn.hook_rot_k', 'blocks.4.attn.hook_attn_scores', 'blocks.4.attn.hook_pattern', 'blocks.4.attn.hook_z', 'blocks.4.hook_attn_out', 'blocks.4.hook_resid_mid', 'blocks.4.ln2.hook_scale', 'blocks.4.ln2.hook_normalized', 'blocks.4.mlp.hook_pre', 'blocks.4.mlp.hook_pre_linear', 'blocks.4.mlp.hook_post', 'blocks.4.hook_mlp_out', 'blocks.4.hook_resid_post', 'blocks.5.hook_resid_pre', 'blocks.5.ln1.hook_scale', 'blocks.5.ln1.hook_normalized', 'blocks.5.attn.hook_q', 'blocks.5.attn.hook_k', 'blocks.5.attn.hook_v', 'blocks.5.attn.hook_rot_q', 'blocks.5.attn.hook_rot_k', 'blocks.5.attn.hook_attn_scores', 'blocks.5.attn.hook_pattern', 'blocks.5.attn.hook_z', 'blocks.5.hook_attn_out', 'blocks.5.hook_resid_mid', 'blocks.5.ln2.hook_scale', 'blocks.5.ln2.hook_normalized', 'blocks.5.mlp.hook_pre', 'blocks.5.mlp.hook_pre_linear', 'blocks.5.mlp.hook_post', 'blocks.5.hook_mlp_out', 'blocks.5.hook_resid_post', 'blocks.6.hook_resid_pre', 'blocks.6.ln1.hook_scale', 'blocks.6.ln1.hook_normalized', 'blocks.6.attn.hook_q', 'blocks.6.attn.hook_k', 'blocks.6.attn.hook_v', 'blocks.6.attn.hook_rot_q', 'blocks.6.attn.hook_rot_k', 'blocks.6.attn.hook_attn_scores', 'blocks.6.attn.hook_pattern', 'blocks.6.attn.hook_z', 'blocks.6.hook_attn_out', 'blocks.6.hook_resid_mid', 'blocks.6.ln2.hook_scale', 'blocks.6.ln2.hook_normalized', 'blocks.6.mlp.hook_pre', 'blocks.6.mlp.hook_pre_linear', 'blocks.6.mlp.hook_post', 'blocks.6.hook_mlp_out', 'blocks.6.hook_resid_post', 'blocks.7.hook_resid_pre', 'blocks.7.ln1.hook_scale', 'blocks.7.ln1.hook_normalized', 'blocks.7.attn.hook_q', 'blocks.7.attn.hook_k', 'blocks.7.attn.hook_v', 'blocks.7.attn.hook_rot_q', 'blocks.7.attn.hook_rot_k', 'blocks.7.attn.hook_attn_scores', 'blocks.7.attn.hook_pattern', 'blocks.7.attn.hook_z', 'blocks.7.hook_attn_out', 'blocks.7.hook_resid_mid', 'blocks.7.ln2.hook_scale', 'blocks.7.ln2.hook_normalized', 'blocks.7.mlp.hook_pre', 'blocks.7.mlp.hook_pre_linear', 'blocks.7.mlp.hook_post', 'blocks.7.hook_mlp_out', 'blocks.7.hook_resid_post', 'blocks.8.hook_resid_pre', 'blocks.8.ln1.hook_scale', 'blocks.8.ln1.hook_normalized', 'blocks.8.attn.hook_q', 'blocks.8.attn.hook_k', 'blocks.8.attn.hook_v', 'blocks.8.attn.hook_rot_q', 'blocks.8.attn.hook_rot_k', 'blocks.8.attn.hook_attn_scores', 'blocks.8.attn.hook_pattern', 'blocks.8.attn.hook_z', 'blocks.8.hook_attn_out', 'blocks.8.hook_resid_mid', 'blocks.8.ln2.hook_scale', 'blocks.8.ln2.hook_normalized', 'blocks.8.mlp.hook_pre', 'blocks.8.mlp.hook_pre_linear', 'blocks.8.mlp.hook_post', 'blocks.8.hook_mlp_out', 'blocks.8.hook_resid_post', 'blocks.9.hook_resid_pre', 'blocks.9.ln1.hook_scale', 'blocks.9.ln1.hook_normalized', 'blocks.9.attn.hook_q', 'blocks.9.attn.hook_k', 'blocks.9.attn.hook_v', 'blocks.9.attn.hook_rot_q', 'blocks.9.attn.hook_rot_k', 'blocks.9.attn.hook_attn_scores', 'blocks.9.attn.hook_pattern', 'blocks.9.attn.hook_z', 'blocks.9.hook_attn_out', 'blocks.9.hook_resid_mid', 'blocks.9.ln2.hook_scale', 'blocks.9.ln2.hook_normalized', 'blocks.9.mlp.hook_pre', 'blocks.9.mlp.hook_pre_linear', 'blocks.9.mlp.hook_post', 'blocks.9.hook_mlp_out', 'blocks.9.hook_resid_post', 'blocks.10.hook_resid_pre', 'blocks.10.ln1.hook_scale', 'blocks.10.ln1.hook_normalized', 'blocks.10.attn.hook_q', 'blocks.10.attn.hook_k', 'blocks.10.attn.hook_v', 'blocks.10.attn.hook_rot_q', 'blocks.10.attn.hook_rot_k', 'blocks.10.attn.hook_attn_scores', 'blocks.10.attn.hook_pattern', 'blocks.10.attn.hook_z', 'blocks.10.hook_attn_out', 'blocks.10.hook_resid_mid', 'blocks.10.ln2.hook_scale', 'blocks.10.ln2.hook_normalized', 'blocks.10.mlp.hook_pre', 'blocks.10.mlp.hook_pre_linear', 'blocks.10.mlp.hook_post', 'blocks.10.hook_mlp_out', 'blocks.10.hook_resid_post', 'blocks.11.hook_resid_pre', 'blocks.11.ln1.hook_scale', 'blocks.11.ln1.hook_normalized', 'blocks.11.attn.hook_q', 'blocks.11.attn.hook_k', 'blocks.11.attn.hook_v', 'blocks.11.attn.hook_rot_q', 'blocks.11.attn.hook_rot_k', 'blocks.11.attn.hook_attn_scores', 'blocks.11.attn.hook_pattern', 'blocks.11.attn.hook_z', 'blocks.11.hook_attn_out', 'blocks.11.hook_resid_mid', 'blocks.11.ln2.hook_scale', 'blocks.11.ln2.hook_normalized', 'blocks.11.mlp.hook_pre', 'blocks.11.mlp.hook_pre_linear', 'blocks.11.mlp.hook_post', 'blocks.11.hook_mlp_out', 'blocks.11.hook_resid_post', 'blocks.12.hook_resid_pre', 'blocks.12.ln1.hook_scale', 'blocks.12.ln1.hook_normalized', 'blocks.12.attn.hook_q', 'blocks.12.attn.hook_k', 'blocks.12.attn.hook_v', 'blocks.12.attn.hook_rot_q', 'blocks.12.attn.hook_rot_k', 'blocks.12.attn.hook_attn_scores', 'blocks.12.attn.hook_pattern', 'blocks.12.attn.hook_z', 'blocks.12.hook_attn_out', 'blocks.12.hook_resid_mid', 'blocks.12.ln2.hook_scale', 'blocks.12.ln2.hook_normalized', 'blocks.12.mlp.hook_pre', 'blocks.12.mlp.hook_pre_linear', 'blocks.12.mlp.hook_post', 'blocks.12.hook_mlp_out', 'blocks.12.hook_resid_post', 'blocks.13.hook_resid_pre', 'blocks.13.ln1.hook_scale', 'blocks.13.ln1.hook_normalized', 'blocks.13.attn.hook_q', 'blocks.13.attn.hook_k', 'blocks.13.attn.hook_v', 'blocks.13.attn.hook_rot_q', 'blocks.13.attn.hook_rot_k', 'blocks.13.attn.hook_attn_scores', 'blocks.13.attn.hook_pattern', 'blocks.13.attn.hook_z', 'blocks.13.hook_attn_out', 'blocks.13.hook_resid_mid', 'blocks.13.ln2.hook_scale', 'blocks.13.ln2.hook_normalized', 'blocks.13.mlp.hook_pre', 'blocks.13.mlp.hook_pre_linear', 'blocks.13.mlp.hook_post', 'blocks.13.hook_mlp_out', 'blocks.13.hook_resid_post', 'blocks.14.hook_resid_pre', 'blocks.14.ln1.hook_scale', 'blocks.14.ln1.hook_normalized', 'blocks.14.attn.hook_q', 'blocks.14.attn.hook_k', 'blocks.14.attn.hook_v', 'blocks.14.attn.hook_rot_q', 'blocks.14.attn.hook_rot_k', 'blocks.14.attn.hook_attn_scores', 'blocks.14.attn.hook_pattern', 'blocks.14.attn.hook_z', 'blocks.14.hook_attn_out', 'blocks.14.hook_resid_mid', 'blocks.14.ln2.hook_scale', 'blocks.14.ln2.hook_normalized', 'blocks.14.mlp.hook_pre', 'blocks.14.mlp.hook_pre_linear', 'blocks.14.mlp.hook_post', 'blocks.14.hook_mlp_out', 'blocks.14.hook_resid_post', 'blocks.15.hook_resid_pre', 'blocks.15.ln1.hook_scale', 'blocks.15.ln1.hook_normalized', 'blocks.15.attn.hook_q', 'blocks.15.attn.hook_k', 'blocks.15.attn.hook_v', 'blocks.15.attn.hook_rot_q', 'blocks.15.attn.hook_rot_k', 'blocks.15.attn.hook_attn_scores', 'blocks.15.attn.hook_pattern', 'blocks.15.attn.hook_z', 'blocks.15.hook_attn_out', 'blocks.15.hook_resid_mid', 'blocks.15.ln2.hook_scale', 'blocks.15.ln2.hook_normalized', 'blocks.15.mlp.hook_pre', 'blocks.15.mlp.hook_pre_linear', 'blocks.15.mlp.hook_post', 'blocks.15.hook_mlp_out', 'blocks.15.hook_resid_post', 'blocks.16.hook_resid_pre', 'blocks.16.ln1.hook_scale', 'blocks.16.ln1.hook_normalized', 'blocks.16.attn.hook_q', 'blocks.16.attn.hook_k', 'blocks.16.attn.hook_v', 'blocks.16.attn.hook_rot_q', 'blocks.16.attn.hook_rot_k', 'blocks.16.attn.hook_attn_scores', 'blocks.16.attn.hook_pattern', 'blocks.16.attn.hook_z', 'blocks.16.hook_attn_out', 'blocks.16.hook_resid_mid', 'blocks.16.ln2.hook_scale', 'blocks.16.ln2.hook_normalized', 'blocks.16.mlp.hook_pre', 'blocks.16.mlp.hook_pre_linear', 'blocks.16.mlp.hook_post', 'blocks.16.hook_mlp_out', 'blocks.16.hook_resid_post', 'blocks.17.hook_resid_pre', 'blocks.17.ln1.hook_scale', 'blocks.17.ln1.hook_normalized', 'blocks.17.attn.hook_q', 'blocks.17.attn.hook_k', 'blocks.17.attn.hook_v', 'blocks.17.attn.hook_rot_q', 'blocks.17.attn.hook_rot_k', 'blocks.17.attn.hook_attn_scores', 'blocks.17.attn.hook_pattern', 'blocks.17.attn.hook_z', 'blocks.17.hook_attn_out', 'blocks.17.hook_resid_mid', 'blocks.17.ln2.hook_scale', 'blocks.17.ln2.hook_normalized', 'blocks.17.mlp.hook_pre', 'blocks.17.mlp.hook_pre_linear', 'blocks.17.mlp.hook_post', 'blocks.17.hook_mlp_out', 'blocks.17.hook_resid_post', 'blocks.18.hook_resid_pre', 'blocks.18.ln1.hook_scale', 'blocks.18.ln1.hook_normalized', 'blocks.18.attn.hook_q', 'blocks.18.attn.hook_k', 'blocks.18.attn.hook_v', 'blocks.18.attn.hook_rot_q', 'blocks.18.attn.hook_rot_k', 'blocks.18.attn.hook_attn_scores', 'blocks.18.attn.hook_pattern', 'blocks.18.attn.hook_z', 'blocks.18.hook_attn_out', 'blocks.18.hook_resid_mid', 'blocks.18.ln2.hook_scale', 'blocks.18.ln2.hook_normalized', 'blocks.18.mlp.hook_pre', 'blocks.18.mlp.hook_pre_linear', 'blocks.18.mlp.hook_post', 'blocks.18.hook_mlp_out', 'blocks.18.hook_resid_post', 'blocks.19.hook_resid_pre', 'blocks.19.ln1.hook_scale', 'blocks.19.ln1.hook_normalized', 'blocks.19.attn.hook_q', 'blocks.19.attn.hook_k', 'blocks.19.attn.hook_v', 'blocks.19.attn.hook_rot_q', 'blocks.19.attn.hook_rot_k', 'blocks.19.attn.hook_attn_scores', 'blocks.19.attn.hook_pattern', 'blocks.19.attn.hook_z', 'blocks.19.hook_attn_out', 'blocks.19.hook_resid_mid', 'blocks.19.ln2.hook_scale', 'blocks.19.ln2.hook_normalized', 'blocks.19.mlp.hook_pre', 'blocks.19.mlp.hook_pre_linear', 'blocks.19.mlp.hook_post', 'blocks.19.hook_mlp_out', 'blocks.19.hook_resid_post', 'blocks.20.hook_resid_pre', 'blocks.20.ln1.hook_scale', 'blocks.20.ln1.hook_normalized', 'blocks.20.attn.hook_q', 'blocks.20.attn.hook_k', 'blocks.20.attn.hook_v', 'blocks.20.attn.hook_rot_q', 'blocks.20.attn.hook_rot_k', 'blocks.20.attn.hook_attn_scores', 'blocks.20.attn.hook_pattern', 'blocks.20.attn.hook_z', 'blocks.20.hook_attn_out', 'blocks.20.hook_resid_mid', 'blocks.20.ln2.hook_scale', 'blocks.20.ln2.hook_normalized', 'blocks.20.mlp.hook_pre', 'blocks.20.mlp.hook_pre_linear', 'blocks.20.mlp.hook_post', 'blocks.20.hook_mlp_out', 'blocks.20.hook_resid_post', 'blocks.21.hook_resid_pre', 'blocks.21.ln1.hook_scale', 'blocks.21.ln1.hook_normalized', 'blocks.21.attn.hook_q', 'blocks.21.attn.hook_k', 'blocks.21.attn.hook_v', 'blocks.21.attn.hook_rot_q', 'blocks.21.attn.hook_rot_k', 'blocks.21.attn.hook_attn_scores', 'blocks.21.attn.hook_pattern', 'blocks.21.attn.hook_z', 'blocks.21.hook_attn_out', 'blocks.21.hook_resid_mid', 'blocks.21.ln2.hook_scale', 'blocks.21.ln2.hook_normalized', 'blocks.21.mlp.hook_pre', 'blocks.21.mlp.hook_pre_linear', 'blocks.21.mlp.hook_post', 'blocks.21.hook_mlp_out', 'blocks.21.hook_resid_post', 'blocks.22.hook_resid_pre', 'blocks.22.ln1.hook_scale', 'blocks.22.ln1.hook_normalized', 'blocks.22.attn.hook_q', 'blocks.22.attn.hook_k', 'blocks.22.attn.hook_v', 'blocks.22.attn.hook_rot_q', 'blocks.22.attn.hook_rot_k', 'blocks.22.attn.hook_attn_scores', 'blocks.22.attn.hook_pattern', 'blocks.22.attn.hook_z', 'blocks.22.hook_attn_out', 'blocks.22.hook_resid_mid', 'blocks.22.ln2.hook_scale', 'blocks.22.ln2.hook_normalized', 'blocks.22.mlp.hook_pre', 'blocks.22.mlp.hook_pre_linear', 'blocks.22.mlp.hook_post', 'blocks.22.hook_mlp_out', 'blocks.22.hook_resid_post', 'blocks.23.hook_resid_pre', 'blocks.23.ln1.hook_scale', 'blocks.23.ln1.hook_normalized', 'blocks.23.attn.hook_q', 'blocks.23.attn.hook_k', 'blocks.23.attn.hook_v', 'blocks.23.attn.hook_rot_q', 'blocks.23.attn.hook_rot_k', 'blocks.23.attn.hook_attn_scores', 'blocks.23.attn.hook_pattern', 'blocks.23.attn.hook_z', 'blocks.23.hook_attn_out', 'blocks.23.hook_resid_mid', 'blocks.23.ln2.hook_scale', 'blocks.23.ln2.hook_normalized', 'blocks.23.mlp.hook_pre', 'blocks.23.mlp.hook_pre_linear', 'blocks.23.mlp.hook_post', 'blocks.23.hook_mlp_out', 'blocks.23.hook_resid_post', 'blocks.24.hook_resid_pre', 'blocks.24.ln1.hook_scale', 'blocks.24.ln1.hook_normalized', 'blocks.24.attn.hook_q', 'blocks.24.attn.hook_k', 'blocks.24.attn.hook_v', 'blocks.24.attn.hook_rot_q', 'blocks.24.attn.hook_rot_k', 'blocks.24.attn.hook_attn_scores', 'blocks.24.attn.hook_pattern', 'blocks.24.attn.hook_z', 'blocks.24.hook_attn_out', 'blocks.24.hook_resid_mid', 'blocks.24.ln2.hook_scale', 'blocks.24.ln2.hook_normalized', 'blocks.24.mlp.hook_pre', 'blocks.24.mlp.hook_pre_linear', 'blocks.24.mlp.hook_post', 'blocks.24.hook_mlp_out', 'blocks.24.hook_resid_post', 'blocks.25.hook_resid_pre', 'blocks.25.ln1.hook_scale', 'blocks.25.ln1.hook_normalized', 'blocks.25.attn.hook_q', 'blocks.25.attn.hook_k', 'blocks.25.attn.hook_v', 'blocks.25.attn.hook_rot_q', 'blocks.25.attn.hook_rot_k', 'blocks.25.attn.hook_attn_scores', 'blocks.25.attn.hook_pattern', 'blocks.25.attn.hook_z', 'blocks.25.hook_attn_out', 'blocks.25.hook_resid_mid', 'blocks.25.ln2.hook_scale', 'blocks.25.ln2.hook_normalized', 'blocks.25.mlp.hook_pre', 'blocks.25.mlp.hook_pre_linear', 'blocks.25.mlp.hook_post', 'blocks.25.hook_mlp_out', 'blocks.25.hook_resid_post', 'blocks.26.hook_resid_pre', 'blocks.26.ln1.hook_scale', 'blocks.26.ln1.hook_normalized', 'blocks.26.attn.hook_q', 'blocks.26.attn.hook_k', 'blocks.26.attn.hook_v', 'blocks.26.attn.hook_rot_q', 'blocks.26.attn.hook_rot_k', 'blocks.26.attn.hook_attn_scores', 'blocks.26.attn.hook_pattern', 'blocks.26.attn.hook_z', 'blocks.26.hook_attn_out', 'blocks.26.hook_resid_mid', 'blocks.26.ln2.hook_scale', 'blocks.26.ln2.hook_normalized', 'blocks.26.mlp.hook_pre', 'blocks.26.mlp.hook_pre_linear', 'blocks.26.mlp.hook_post', 'blocks.26.hook_mlp_out', 'blocks.26.hook_resid_post', 'blocks.27.hook_resid_pre', 'blocks.27.ln1.hook_scale', 'blocks.27.ln1.hook_normalized', 'blocks.27.attn.hook_q', 'blocks.27.attn.hook_k', 'blocks.27.attn.hook_v', 'blocks.27.attn.hook_rot_q', 'blocks.27.attn.hook_rot_k', 'blocks.27.attn.hook_attn_scores', 'blocks.27.attn.hook_pattern', 'blocks.27.attn.hook_z', 'blocks.27.hook_attn_out', 'blocks.27.hook_resid_mid', 'blocks.27.ln2.hook_scale', 'blocks.27.ln2.hook_normalized', 'blocks.27.mlp.hook_pre', 'blocks.27.mlp.hook_pre_linear', 'blocks.27.mlp.hook_post', 'blocks.27.hook_mlp_out', 'blocks.27.hook_resid_post', 'blocks.28.hook_resid_pre', 'blocks.28.ln1.hook_scale', 'blocks.28.ln1.hook_normalized', 'blocks.28.attn.hook_q', 'blocks.28.attn.hook_k', 'blocks.28.attn.hook_v', 'blocks.28.attn.hook_rot_q', 'blocks.28.attn.hook_rot_k', 'blocks.28.attn.hook_attn_scores', 'blocks.28.attn.hook_pattern', 'blocks.28.attn.hook_z', 'blocks.28.hook_attn_out', 'blocks.28.hook_resid_mid', 'blocks.28.ln2.hook_scale', 'blocks.28.ln2.hook_normalized', 'blocks.28.mlp.hook_pre', 'blocks.28.mlp.hook_pre_linear', 'blocks.28.mlp.hook_post', 'blocks.28.hook_mlp_out', 'blocks.28.hook_resid_post', 'blocks.29.hook_resid_pre', 'blocks.29.ln1.hook_scale', 'blocks.29.ln1.hook_normalized', 'blocks.29.attn.hook_q', 'blocks.29.attn.hook_k', 'blocks.29.attn.hook_v', 'blocks.29.attn.hook_rot_q', 'blocks.29.attn.hook_rot_k', 'blocks.29.attn.hook_attn_scores', 'blocks.29.attn.hook_pattern', 'blocks.29.attn.hook_z', 'blocks.29.hook_attn_out', 'blocks.29.hook_resid_mid', 'blocks.29.ln2.hook_scale', 'blocks.29.ln2.hook_normalized', 'blocks.29.mlp.hook_pre', 'blocks.29.mlp.hook_pre_linear', 'blocks.29.mlp.hook_post', 'blocks.29.hook_mlp_out', 'blocks.29.hook_resid_post', 'blocks.30.hook_resid_pre', 'blocks.30.ln1.hook_scale', 'blocks.30.ln1.hook_normalized', 'blocks.30.attn.hook_q', 'blocks.30.attn.hook_k', 'blocks.30.attn.hook_v', 'blocks.30.attn.hook_rot_q', 'blocks.30.attn.hook_rot_k', 'blocks.30.attn.hook_attn_scores', 'blocks.30.attn.hook_pattern', 'blocks.30.attn.hook_z', 'blocks.30.hook_attn_out', 'blocks.30.hook_resid_mid', 'blocks.30.ln2.hook_scale', 'blocks.30.ln2.hook_normalized', 'blocks.30.mlp.hook_pre', 'blocks.30.mlp.hook_pre_linear', 'blocks.30.mlp.hook_post', 'blocks.30.hook_mlp_out', 'blocks.30.hook_resid_post', 'blocks.31.hook_resid_pre', 'blocks.31.ln1.hook_scale', 'blocks.31.ln1.hook_normalized', 'blocks.31.attn.hook_q', 'blocks.31.attn.hook_k', 'blocks.31.attn.hook_v', 'blocks.31.attn.hook_rot_q', 'blocks.31.attn.hook_rot_k', 'blocks.31.attn.hook_attn_scores', 'blocks.31.attn.hook_pattern', 'blocks.31.attn.hook_z', 'blocks.31.hook_attn_out', 'blocks.31.hook_resid_mid', 'blocks.31.ln2.hook_scale', 'blocks.31.ln2.hook_normalized', 'blocks.31.mlp.hook_pre', 'blocks.31.mlp.hook_pre_linear', 'blocks.31.mlp.hook_post', 'blocks.31.hook_mlp_out', 'blocks.31.hook_resid_post', 'ln_final.hook_scale', 'ln_final.hook_normalized'])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cache.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c605ae87",
   "metadata": {},
   "outputs": [],
   "source": [
    "hooks = []\n",
    "conditioning_values = {}\n",
    "for lix, nix in neuron_list:\n",
    "    conditioning_values[(lix,nix)]={}\n",
    "    hooks += make_hooks(\n",
    "        args,\n",
    "        lix, nix,\n",
    "        conditioning_value=conditioning_values[(lix,nix)],\n",
    "        sign=(model.W_gate[lix,:,nix]@model.W_in[lix,:,nix]).item(),\n",
    "        mean_value=0.0,\n",
    "    )\n",
    "#print(hooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4df9c837",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_ablated = model.run_with_hooks(my_input_ids, fwd_hooks=hooks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd780e6c",
   "metadata": {},
   "source": [
    "## Finding relevant tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8cd565d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_diff = logits - logits_ablated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b12554d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 96, 50304])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_diff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "11bb30c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50304])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_logit_diff = logit_diff[0,25,:]\n",
    "relevant_logit_diff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1c41b278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([12.5329,  7.1575,  7.1229,  6.8121,  6.7228,  6.5633,  6.5550,  6.5279,\n",
      "         6.2066,  6.1819,  6.1671,  5.9645,  5.8675,  5.6778,  5.6114,  5.5637],\n",
      "       device='cuda:6', grad_fn=<TopkBackward0>),\n",
      "indices=tensor([ 6185,  6402,  7373, 10929, 34611, 28184, 18227,  8555, 43441,  2494,\n",
      "         4883, 12761, 25810, 36132,  1814, 16192], device='cuda:6'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([-3.3217, -3.2983, -3.2578, -3.1851, -3.1702, -3.1052, -3.1043, -3.0887,\n",
      "        -3.0541, -3.0457, -2.9698, -2.9301, -2.9189, -2.9149, -2.9032, -2.8691],\n",
      "       device='cuda:6', grad_fn=<TopkBackward0>),\n",
      "indices=tensor([12444, 16828,   214,  9676,  5020, 10713,  1972, 22165,   800,  3504,\n",
      "        24761, 13793, 33158,  3153,   731,  1718], device='cuda:6'))\n"
     ]
    }
   ],
   "source": [
    "top = torch.topk(relevant_logit_diff, k=16)\n",
    "bottom = torch.topk(relevant_logit_diff, k=16, largest=False)\n",
    "print(top)\n",
    "print(bottom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0b032f66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mic',\n",
       " 'MI',\n",
       " 'mi',\n",
       " ' Mic',\n",
       " 'MIC',\n",
       " 'Mic',\n",
       " 'micro',\n",
       " ' mic',\n",
       " 'yster',\n",
       " ' micro',\n",
       " 'NS',\n",
       " ' Micro',\n",
       " 'Micro',\n",
       " 'microm',\n",
       " 'mb',\n",
       " 'mn']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to_str_tokens(top.indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e51b38ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['об',\n",
       " 'ру',\n",
       " '�',\n",
       " ' illegal',\n",
       " ' majority',\n",
       " ' bulk',\n",
       " 'ances',\n",
       " ' Wayne',\n",
       " 'ative',\n",
       " 'я',\n",
       " 'houses',\n",
       " 'ع',\n",
       " '\\n\\t\\t\\n\\t',\n",
       " ' live',\n",
       " ' them',\n",
       " ' invest']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to_str_tokens(bottom.indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5cbe5d21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|endoftext|>', ' O', 'mic', 'ron']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to_str_tokens(' Omicron')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a3e1ad",
   "metadata": {},
   "source": [
    "## Ablating weakening neurons generally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "934d8d43",
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 5.38 GiB. GPU 6 has a total capacity of 47.40 GiB of which 2.41 GiB is free. Including non-PyTorch memory, this process has 44.98 GiB memory in use. Of the allocated memory 41.08 GiB is allocated by PyTorch, and 3.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[78]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m lix, nix \u001b[38;5;129;01min\u001b[39;00m neuron_list:\n\u001b[32m      7\u001b[39m     conditioning_values[(lix,nix)]={}\n\u001b[32m      8\u001b[39m     hooks_general += make_hooks(\n\u001b[32m      9\u001b[39m         args,\n\u001b[32m     10\u001b[39m         lix, nix,\n\u001b[32m     11\u001b[39m         conditioning_value=conditioning_values[(lix,nix)],\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m         sign=(model.W_gate[lix,:,nix]\u001b[38;5;129m@model\u001b[39m.W_in[lix,:,nix]).item(),\n\u001b[32m     13\u001b[39m         mean_value=\u001b[32m0.0\u001b[39m,\n\u001b[32m     14\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mounts/work/sgerstner/RW_functionalities/TransformerLens/transformer_lens/HookedTransformer.py:2479\u001b[39m, in \u001b[36mHookedTransformer.W_gate\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2474\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Stack the MLP gate weights across all layers.\u001b[39;00m\n\u001b[32m   2475\u001b[39m \n\u001b[32m   2476\u001b[39m \u001b[33;03mOnly works for models with gated MLPs.\u001b[39;00m\n\u001b[32m   2477\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2478\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cfg.gated_mlp:\n\u001b[32m-> \u001b[39m\u001b[32m2479\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.stack([block.mlp.W_gate \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.blocks], dim=\u001b[32m0\u001b[39m)\n\u001b[32m   2480\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2481\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 5.38 GiB. GPU 6 has a total capacity of 47.40 GiB of which 2.41 GiB is free. Including non-PyTorch memory, this process has 44.98 GiB memory in use. Of the allocated memory 41.08 GiB is allocated by PyTorch, and 3.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "args.gate=None\n",
    "args.post=None\n",
    "\n",
    "hooks_general = []\n",
    "conditioning_values = {}\n",
    "for lix, nix in neuron_list:\n",
    "    conditioning_values[(lix,nix)]={}\n",
    "    hooks_general += make_hooks(\n",
    "        args,\n",
    "        lix, nix,\n",
    "        conditioning_value=conditioning_values[(lix,nix)],\n",
    "        sign=(model.W_gate[lix,:,nix]@model.W_in[lix,:,nix]).item(),\n",
    "        mean_value=0.0,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0711017a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9be98de5",
   "metadata": {},
   "source": [
    "## Is there a single neuron responsible for this?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec964a8b",
   "metadata": {},
   "source": [
    "We're looking for a weakening neuron whose $w_\\text{out}$ corresponds as closely as possible to the token 'mic'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c83b2904",
   "metadata": {},
   "outputs": [],
   "source": [
    "mic = model.W_U[:,model.to_single_token('mic')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5972e086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-5.5654e-03, -1.9865e-02,  2.3740e-03,  2.3131e-03, -1.0920e-02,\n",
      "        -1.1843e-02, -5.0423e-03,  6.3631e-05,  6.2427e-03, -2.7632e-03,\n",
      "        -1.7804e-02, -3.3106e-03, -2.4462e-02,  1.4472e-02,  3.5042e-03,\n",
      "         1.0408e-03, -6.3770e-03,  1.5915e-02, -7.3378e-03,  4.2016e-03,\n",
      "        -2.5157e-02, -1.2029e-02, -4.9860e-04,  2.5065e-03,  1.2379e-02,\n",
      "        -1.4918e-02, -3.8517e-03,  6.9253e-04,  1.1168e-02, -1.2686e-02,\n",
      "        -2.5985e-02, -1.1120e-02,  6.2533e-02, -4.0599e-04,  4.4302e-03,\n",
      "        -7.2232e-05,  2.3728e-02, -7.4714e-03, -2.7623e-03, -9.6072e-03,\n",
      "        -7.5862e-03, -3.2695e-02, -1.2145e-03, -1.2980e-02, -6.6941e-04,\n",
      "         3.1989e-02, -3.7805e-03,  1.3651e-02, -6.6925e-03, -8.9840e-04,\n",
      "        -2.2595e-02,  7.9196e-03,  1.5796e-02, -8.6340e-03, -5.0332e-04,\n",
      "         3.4942e-04, -1.7101e-02,  8.4782e-03, -2.1459e-03, -1.4602e-02,\n",
      "         4.4703e-03,  4.5846e-03,  5.6527e-03,  1.0334e-02, -2.8266e-03,\n",
      "         1.0407e-02, -1.4816e-02,  1.0181e-03, -2.0441e-03, -7.9895e-03,\n",
      "         9.2492e-03, -3.3607e-03,  3.5227e-02,  1.2421e-02,  2.2272e-02,\n",
      "         3.5134e-02, -1.0150e-02,  3.4365e-04, -7.0647e-03, -4.3011e-03,\n",
      "         1.6703e-01, -7.7391e-03,  9.4281e-03,  4.1831e-03, -6.2609e-03,\n",
      "        -1.6635e-02, -9.6335e-03, -2.5775e-03, -7.6044e-03,  9.0736e-03,\n",
      "         1.7292e-02,  4.0892e-03, -3.4577e-03,  8.0882e-03, -2.8934e-03,\n",
      "         2.4911e-02, -2.9553e-02,  1.4572e-02, -2.5937e-03,  4.9188e-03,\n",
      "        -8.1271e-03,  1.0230e-02,  4.2897e-03,  1.8471e-03, -3.6221e-03,\n",
      "        -4.5176e-02, -2.4613e-03,  1.3402e-03, -6.4679e-03, -1.3322e-02,\n",
      "         2.5975e-02, -3.3556e-02,  4.8628e-03, -1.1124e-03, -1.3948e-02,\n",
      "         9.2180e-03,  3.0183e-03, -7.7761e-03,  6.6318e-03, -6.2454e-03,\n",
      "        -1.4202e-02,  1.9294e-02, -8.9975e-04,  8.2946e-03,  4.0775e-03,\n",
      "         5.4591e-03, -5.6742e-03,  6.2610e-03, -3.5535e-03, -8.5859e-04,\n",
      "         1.9576e-02,  3.5671e-03,  9.5594e-03, -7.1190e-03, -8.2757e-03,\n",
      "        -2.4627e-02,  5.8774e-03, -1.9354e-02,  3.2083e-02,  5.4887e-04,\n",
      "        -1.8251e-03,  3.2712e-02, -4.9627e-03, -2.8580e-03,  2.2363e-02,\n",
      "         4.2831e-03, -1.7257e-02, -3.1238e-03,  4.1873e-02, -1.2262e-03,\n",
      "        -1.1404e-02, -3.3379e-04,  5.7038e-03, -4.9630e-03, -9.3134e-04,\n",
      "         3.2711e-02,  1.4099e-02, -6.1890e-03, -1.2179e-02, -2.0915e-02,\n",
      "        -1.4448e-02,  7.3019e-03, -9.8016e-03,  2.4650e-03,  1.8396e-02,\n",
      "         8.0120e-04,  1.1479e-02, -7.7214e-03,  1.1099e-01, -3.7451e-03,\n",
      "        -3.4326e-03, -1.0480e-02, -8.3944e-03,  3.2822e-02, -3.0652e-04,\n",
      "         3.8925e-03,  6.9445e-03,  2.8455e-03,  1.1254e-03, -7.2715e-04,\n",
      "        -1.4079e-02, -9.2646e-04, -2.5498e-02, -2.1066e-02, -3.6782e-03,\n",
      "         2.9500e-03,  1.4502e-03, -2.7085e-02,  1.7520e-03,  7.5109e-03,\n",
      "        -1.1267e-03, -3.4825e-03,  1.1716e-03, -1.0791e-02, -9.7286e-03,\n",
      "         1.8739e-02,  4.7546e-03,  9.8260e-03,  4.7647e-03, -9.5568e-03,\n",
      "        -7.4834e-03, -5.2763e-03, -1.6181e-02, -4.2685e-03,  4.8152e-02,\n",
      "        -1.1209e-02,  2.4606e-02, -1.2259e-03,  1.4911e-02,  6.7225e-03,\n",
      "        -8.0408e-03,  4.7149e-03, -1.1012e-02, -4.8037e-03,  6.8458e-03,\n",
      "        -2.7527e-02,  6.1501e-03, -5.8549e-03,  4.6129e-03, -1.9232e-02,\n",
      "         6.2308e-03,  6.0249e-03,  1.0420e-02, -9.5669e-03,  3.7512e-03,\n",
      "         4.7453e-03,  1.3389e-03, -2.2484e-03,  2.3390e-03, -1.0543e-03,\n",
      "         9.8042e-03, -6.6439e-03, -1.8821e-02,  3.5331e-03,  2.1838e-03,\n",
      "         2.0130e-03, -5.0644e-03, -2.4453e-03, -1.2884e-02, -4.6698e-03,\n",
      "         7.7333e-03,  1.2097e-02, -2.0617e-02])\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for l,n in neuron_list:\n",
    "    wout = model.W_out[l,n]\n",
    "    wout /= torch.norm(wout)\n",
    "    scores.append(wout@mic)\n",
    "scores = torch.tensor(scores)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1cac6beb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([0.1670, 0.1110, 0.0625, 0.0482, 0.0419, 0.0352, 0.0351, 0.0328, 0.0327,\n",
       "        0.0327, 0.0321, 0.0320, 0.0260, 0.0249, 0.0246, 0.0237]),\n",
       "indices=tensor([ 80, 168,  32, 204, 148,  72,  75, 173, 141, 155, 138,  45, 110,  95,\n",
       "        206,  36]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.topk(scores, k=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8042866c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([-0.0452, -0.0336, -0.0327, -0.0296, -0.0275, -0.0271, -0.0260, -0.0255,\n",
       "        -0.0252, -0.0246, -0.0245, -0.0226, -0.0211, -0.0209, -0.0206, -0.0199]),\n",
       "indices=tensor([105, 111,  41,  96, 215, 187,  30, 182,  20, 135,  12,  50, 183, 159,\n",
       "        242,   1]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.topk(scores, k=16, largest=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "59a874ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(31, device='cuda:0'), tensor(3498, device='cuda:0'))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neuron_list[80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dd0a143d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('re', tensor(0.1918, device='cuda:6'))\n",
      "('b', tensor(0.1895, device='cuda:6'))\n",
      "('c', tensor(0.1863, device='cuda:6'))\n",
      "('w', tensor(0.1831, device='cuda:6'))\n",
      "('p', tensor(0.1822, device='cuda:6'))\n",
      "('g', tensor(0.1808, device='cuda:6'))\n",
      "('to', tensor(0.1789, device='cuda:6'))\n",
      "('f', tensor(0.1776, device='cuda:6'))\n",
      "('m', tensor(0.1770, device='cuda:6'))\n",
      "('st', tensor(0.1760, device='cuda:6'))\n",
      "('sh', tensor(0.1730, device='cuda:6'))\n",
      "('de', tensor(0.1711, device='cuda:6'))\n",
      "('d', tensor(0.1711, device='cuda:6'))\n",
      "('t', tensor(0.1700, device='cuda:6'))\n",
      "('h', tensor(0.1699, device='cuda:6'))\n",
      "('se', tensor(0.1661, device='cuda:6'))\n"
     ]
    }
   ],
   "source": [
    "values, indices = torch.topk(model.blocks[31].mlp.W_out[3498,:]@model.W_U, k=16)\n",
    "for j in range(16):\n",
    "    print((model.to_single_str_token(indices[j].item()), values[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fb36c170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([33027, 44794, 11722, 17507, 46631, 25442, 34436, 23220, 11846, 34613,\n",
      "        46425, 25834, 46371,  5025, 15681, 22796, 31459,  8902, 36383, 11759,\n",
      "        49177, 37462, 25061, 18214,  8414, 38222, 34092, 20984,  8966, 43250,\n",
      "        48547, 35267,  1817, 25002, 11094, 23719,   204, 22263, 34918, 49288,\n",
      "        43525, 32577, 27633, 26429, 24108,  8951, 36769,  5448, 34544, 22052,\n",
      "        49540,  4933,  5594, 40541, 23993, 21516, 40685,  9317, 31069, 45143,\n",
      "        16945, 13908,  9458,  8681, 33606,  7666, 45361, 18988, 28537, 36553,\n",
      "         3530, 27726,  5330,  7637,  2332,  3959, 42244, 21798, 44665, 28791,\n",
      "          767, 43145, 14870, 10781, 29001, 45069, 48040, 27130, 45341,  3937,\n",
      "         4669, 12602, 35360,  3953, 34059,  3986, 48969,  2957, 25602, 13362,\n",
      "        47640,  1403, 12754, 20264, 25564, 31879, 29734, 16825, 36359, 44763,\n",
      "          360, 49651, 14619, 26784, 24379, 10822, 17850, 35104, 13581, 34743,\n",
      "        43165,  1346, 27405,  4292,  8312, 15292, 32876, 12042, 35807, 22554,\n",
      "          739, 15126, 11611, 44691, 43722, 48579, 15429, 31935,  7223, 21535,\n",
      "        27866,  8488, 40097, 29459,  1142, 16139, 46559, 28335,  4514, 23113,\n",
      "        47286, 24189, 14398, 36558, 26281,  4595,  6262, 32726, 47892, 47808,\n",
      "        42244, 10855, 41656, 20057,  3262, 21718, 16421, 44373,  2200, 26219,\n",
      "        28622, 47062, 42341,  3931, 19588, 11126, 13548, 17524, 15006, 27138,\n",
      "        38348, 26995, 47864, 29867, 23482, 19026, 19162, 48998, 19239,  3340,\n",
      "        27326, 30353, 20122, 45964, 39988,  3006, 15565, 10910, 13267, 45365,\n",
      "        38286, 41044, 45446, 42316,  6153, 48822, 11723, 28922, 12752, 12974,\n",
      "        42367, 10306, 42649, 31691,  6438, 43951,  6029, 36956, 14749, 29125,\n",
      "        11396,  5763,  4020, 39850, 17227, 15412, 19239, 26773, 11179, 24631,\n",
      "         4680, 43890, 47088, 16165, 17627, 16623, 33666, 31956, 41063, 30203,\n",
      "         8553,  6757, 48190])\n",
      "torch.return_types.topk(\n",
      "values=tensor([49651, 49540, 49288, 49177, 48998, 48969, 48822, 48579, 48547, 48190,\n",
      "        48040, 47892, 47864, 47808, 47640, 47286]),\n",
      "indices=tensor([111,  50,  39,  20, 187,  96, 205, 135,  30, 242,  86, 158, 182, 159,\n",
      "        100, 150]))\n"
     ]
    }
   ],
   "source": [
    "ranks = []\n",
    "for i,(l,n) in enumerate(neuron_list):\n",
    "    wout = model.blocks[l].mlp.W_out[n,:]\n",
    "    wout /= torch.norm(wout)\n",
    "    all_scores = wout@model.W_U\n",
    "    ranks.append(torch.count_nonzero(all_scores>scores[i])-1)\n",
    "ranks = torch.tensor(ranks)\n",
    "print(ranks)\n",
    "print(torch.topk(ranks, k=16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ffc9c512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([ 204,  360,  739,  767, 1142, 1346, 1403, 1817, 2200, 2332, 2957, 3006,\n",
       "        3262, 3340, 3530, 3931]),\n",
       "indices=tensor([ 36, 110, 130,  80, 144, 121, 101,  32, 168,  74,  97, 195, 164, 189,\n",
       "         70, 173]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.topk(ranks, k=16, largest=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f1609efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9dbb71fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d92db5",
   "metadata": {},
   "source": [
    "## Analysing model hidden states on the example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1bc785ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================\n",
      "Layer 0, mid:\n",
      "([' in'], tensor(0.2816, device='cuda:6'))\n",
      "([' of'], tensor(0.2600, device='cuda:6'))\n",
      "(['\\n'], tensor(0.2556, device='cuda:6'))\n",
      "([' then'], tensor(0.2409, device='cuda:6'))\n",
      "===========================\n",
      "Layer 0, post:\n",
      "([\"'\"], tensor(0.3902, device='cuda:6'))\n",
      "(['-'], tensor(0.3567, device='cuda:6'))\n",
      "(['ops'], tensor(0.3376, device='cuda:6'))\n",
      "(['xygen'], tensor(0.3136, device='cuda:6'))\n",
      "===========================\n",
      "Layer 1, mid:\n",
      "(['xygen'], tensor(0.3256, device='cuda:6'))\n",
      "([\"'\"], tensor(0.3223, device='cuda:6'))\n",
      "(['ops'], tensor(0.3137, device='cuda:6'))\n",
      "(['ats'], tensor(0.3126, device='cuda:6'))\n",
      "===========================\n",
      "Layer 1, post:\n",
      "(['xygen'], tensor(0.3145, device='cuda:6'))\n",
      "(['ats'], tensor(0.2860, device='cuda:6'))\n",
      "(['asis'], tensor(0.2826, device='cuda:6'))\n",
      "(['ops'], tensor(0.2819, device='cuda:6'))\n",
      "===========================\n",
      "Layer 2, mid:\n",
      "(['xygen'], tensor(0.3330, device='cuda:6'))\n",
      "(['cean'], tensor(0.3086, device='cuda:6'))\n",
      "(['asis'], tensor(0.2923, device='cuda:6'))\n",
      "(['ceans'], tensor(0.2916, device='cuda:6'))\n",
      "===========================\n",
      "Layer 2, post:\n",
      "(['xygen'], tensor(0.3385, device='cuda:6'))\n",
      "(['cean'], tensor(0.2971, device='cuda:6'))\n",
      "(['BE'], tensor(0.2837, device='cuda:6'))\n",
      "(['ceans'], tensor(0.2814, device='cuda:6'))\n",
      "===========================\n",
      "Layer 3, mid:\n",
      "(['xygen'], tensor(0.3423, device='cuda:6'))\n",
      "(['cean'], tensor(0.2969, device='cuda:6'))\n",
      "(['ceans'], tensor(0.2838, device='cuda:6'))\n",
      "(['equ'], tensor(0.2796, device='cuda:6'))\n",
      "===========================\n",
      "Layer 3, post:\n",
      "(['xygen'], tensor(0.3599, device='cuda:6'))\n",
      "(['ops'], tensor(0.3491, device='cuda:6'))\n",
      "(['yster'], tensor(0.3216, device='cuda:6'))\n",
      "(['ceans'], tensor(0.3166, device='cuda:6'))\n",
      "===========================\n",
      "Layer 4, mid:\n",
      "(['ops'], tensor(0.3458, device='cuda:6'))\n",
      "(['xygen'], tensor(0.3329, device='cuda:6'))\n",
      "(['BA'], tensor(0.3206, device='cuda:6'))\n",
      "(['yster'], tensor(0.3086, device='cuda:6'))\n",
      "===========================\n",
      "Layer 4, post:\n",
      "(['xygen'], tensor(0.4415, device='cuda:6'))\n",
      "(['BA'], tensor(0.4350, device='cuda:6'))\n",
      "(['yster'], tensor(0.4014, device='cuda:6'))\n",
      "(['DE'], tensor(0.3972, device='cuda:6'))\n",
      "===========================\n",
      "Layer 5, mid:\n",
      "(['BA'], tensor(0.4521, device='cuda:6'))\n",
      "(['CC'], tensor(0.4356, device='cuda:6'))\n",
      "(['xygen'], tensor(0.4316, device='cuda:6'))\n",
      "(['CR'], tensor(0.3992, device='cuda:6'))\n",
      "===========================\n",
      "Layer 5, post:\n",
      "(['DE'], tensor(0.4178, device='cuda:6'))\n",
      "(['CC'], tensor(0.4054, device='cuda:6'))\n",
      "(['BA'], tensor(0.4011, device='cuda:6'))\n",
      "(['FA'], tensor(0.3960, device='cuda:6'))\n",
      "===========================\n",
      "Layer 6, mid:\n",
      "(['DE'], tensor(0.4475, device='cuda:6'))\n",
      "(['LE'], tensor(0.4325, device='cuda:6'))\n",
      "(['BA'], tensor(0.4286, device='cuda:6'))\n",
      "(['CR'], tensor(0.4090, device='cuda:6'))\n",
      "===========================\n",
      "Layer 6, post:\n",
      "(['LE'], tensor(0.4497, device='cuda:6'))\n",
      "(['asis'], tensor(0.4439, device='cuda:6'))\n",
      "(['xygen'], tensor(0.4436, device='cuda:6'))\n",
      "(['ahu'], tensor(0.4213, device='cuda:6'))\n",
      "===========================\n",
      "Layer 7, mid:\n",
      "(['LE'], tensor(0.4325, device='cuda:6'))\n",
      "(['asis'], tensor(0.4290, device='cuda:6'))\n",
      "(['BA'], tensor(0.4283, device='cuda:6'))\n",
      "(['xygen'], tensor(0.4164, device='cuda:6'))\n",
      "===========================\n",
      "Layer 7, post:\n",
      "(['xygen'], tensor(0.4680, device='cuda:6'))\n",
      "(['yster'], tensor(0.4599, device='cuda:6'))\n",
      "(['ahu'], tensor(0.4568, device='cuda:6'))\n",
      "(['ceans'], tensor(0.4526, device='cuda:6'))\n",
      "===========================\n",
      "Layer 8, mid:\n",
      "(['ahu'], tensor(0.4683, device='cuda:6'))\n",
      "(['ceans'], tensor(0.4673, device='cuda:6'))\n",
      "(['xygen'], tensor(0.4588, device='cuda:6'))\n",
      "(['yster'], tensor(0.4509, device='cuda:6'))\n",
      "===========================\n",
      "Layer 8, post:\n",
      "(['xygen'], tensor(0.4986, device='cuda:6'))\n",
      "(['ceans'], tensor(0.4873, device='cuda:6'))\n",
      "(['yster'], tensor(0.4845, device='cuda:6'))\n",
      "(['asis'], tensor(0.4668, device='cuda:6'))\n",
      "===========================\n",
      "Layer 9, mid:\n",
      "(['xygen'], tensor(0.4820, device='cuda:6'))\n",
      "(['ceans'], tensor(0.4807, device='cuda:6'))\n",
      "(['yster'], tensor(0.4716, device='cuda:6'))\n",
      "(['asis'], tensor(0.4485, device='cuda:6'))\n",
      "===========================\n",
      "Layer 9, post:\n",
      "([' COVID'], tensor(0.5217, device='cuda:6'))\n",
      "(['ceans'], tensor(0.5112, device='cuda:6'))\n",
      "(['ught'], tensor(0.4808, device='cuda:6'))\n",
      "(['xygen'], tensor(0.4797, device='cuda:6'))\n",
      "===========================\n",
      "Layer 10, mid:\n",
      "([' COVID'], tensor(0.5406, device='cuda:6'))\n",
      "(['ceans'], tensor(0.5048, device='cuda:6'))\n",
      "(['ught'], tensor(0.4788, device='cuda:6'))\n",
      "(['asis'], tensor(0.4772, device='cuda:6'))\n",
      "===========================\n",
      "Layer 10, post:\n",
      "(['ceans'], tensor(0.5270, device='cuda:6'))\n",
      "([' COVID'], tensor(0.5268, device='cuda:6'))\n",
      "(['xygen'], tensor(0.5061, device='cuda:6'))\n",
      "(['asis'], tensor(0.4854, device='cuda:6'))\n",
      "===========================\n",
      "Layer 11, mid:\n",
      "([' COVID'], tensor(0.5312, device='cuda:6'))\n",
      "(['ceans'], tensor(0.5232, device='cuda:6'))\n",
      "(['xygen'], tensor(0.5124, device='cuda:6'))\n",
      "(['asis'], tensor(0.4888, device='cuda:6'))\n",
      "===========================\n",
      "Layer 11, post:\n",
      "(['ceans'], tensor(0.5157, device='cuda:6'))\n",
      "([' COVID'], tensor(0.5105, device='cuda:6'))\n",
      "(['yst'], tensor(0.5069, device='cuda:6'))\n",
      "(['xygen'], tensor(0.5000, device='cuda:6'))\n",
      "===========================\n",
      "Layer 12, mid:\n",
      "([' COVID'], tensor(0.5346, device='cuda:6'))\n",
      "(['ceans'], tensor(0.5197, device='cuda:6'))\n",
      "(['yst'], tensor(0.5116, device='cuda:6'))\n",
      "(['xygen'], tensor(0.5079, device='cuda:6'))\n",
      "===========================\n",
      "Layer 12, post:\n",
      "([' COVID'], tensor(0.5646, device='cuda:6'))\n",
      "(['yst'], tensor(0.5188, device='cuda:6'))\n",
      "(['ceans'], tensor(0.5110, device='cuda:6'))\n",
      "(['xygen'], tensor(0.5017, device='cuda:6'))\n",
      "===========================\n",
      "Layer 13, mid:\n",
      "([' COVID'], tensor(0.5673, device='cuda:6'))\n",
      "(['yst'], tensor(0.5242, device='cuda:6'))\n",
      "(['ceans'], tensor(0.5123, device='cuda:6'))\n",
      "(['xygen'], tensor(0.5019, device='cuda:6'))\n",
      "===========================\n",
      "Layer 13, post:\n",
      "(['yst'], tensor(0.5571, device='cuda:6'))\n",
      "(['ceans'], tensor(0.5215, device='cuda:6'))\n",
      "(['xygen'], tensor(0.5150, device='cuda:6'))\n",
      "([' COVID'], tensor(0.5132, device='cuda:6'))\n",
      "===========================\n",
      "Layer 14, mid:\n",
      "([' COVID'], tensor(0.5887, device='cuda:6'))\n",
      "(['yst'], tensor(0.5605, device='cuda:6'))\n",
      "(['ceans'], tensor(0.5259, device='cuda:6'))\n",
      "(['xygen'], tensor(0.5252, device='cuda:6'))\n",
      "===========================\n",
      "Layer 14, post:\n",
      "(['yst'], tensor(0.5720, device='cuda:6'))\n",
      "(['yster'], tensor(0.5453, device='cuda:6'))\n",
      "([' COVID'], tensor(0.5425, device='cuda:6'))\n",
      "(['xygen'], tensor(0.5414, device='cuda:6'))\n",
      "===========================\n",
      "Layer 15, mid:\n",
      "([' COVID'], tensor(0.5963, device='cuda:6'))\n",
      "(['yst'], tensor(0.5650, device='cuda:6'))\n",
      "(['yster'], tensor(0.5565, device='cuda:6'))\n",
      "(['xygen'], tensor(0.5395, device='cuda:6'))\n",
      "===========================\n",
      "Layer 15, post:\n",
      "([' COVID'], tensor(0.5790, device='cuda:6'))\n",
      "(['yst'], tensor(0.5579, device='cuda:6'))\n",
      "(['yster'], tensor(0.5321, device='cuda:6'))\n",
      "(['ceans'], tensor(0.5228, device='cuda:6'))\n",
      "===========================\n",
      "Layer 16, mid:\n",
      "([' COVID'], tensor(0.5900, device='cuda:6'))\n",
      "(['yst'], tensor(0.5712, device='cuda:6'))\n",
      "(['yster'], tensor(0.5385, device='cuda:6'))\n",
      "(['ceans'], tensor(0.5363, device='cuda:6'))\n",
      "===========================\n",
      "Layer 16, post:\n",
      "(['yst'], tensor(0.6023, device='cuda:6'))\n",
      "(['xygen'], tensor(0.5479, device='cuda:6'))\n",
      "([' COVID'], tensor(0.5382, device='cuda:6'))\n",
      "(['yster'], tensor(0.5361, device='cuda:6'))\n",
      "===========================\n",
      "Layer 17, mid:\n",
      "(['yst'], tensor(0.6057, device='cuda:6'))\n",
      "(['xygen'], tensor(0.5520, device='cuda:6'))\n",
      "([' COVID'], tensor(0.5418, device='cuda:6'))\n",
      "(['yster'], tensor(0.5378, device='cuda:6'))\n",
      "===========================\n",
      "Layer 17, post:\n",
      "([' COVID'], tensor(0.8083, device='cuda:6'))\n",
      "([' coronavirus'], tensor(0.6614, device='cuda:6'))\n",
      "([' Cov'], tensor(0.6458, device='cuda:6'))\n",
      "(['yst'], tensor(0.6139, device='cuda:6'))\n",
      "===========================\n",
      "Layer 18, mid:\n",
      "([' COVID'], tensor(0.8180, device='cuda:6'))\n",
      "([' coronavirus'], tensor(0.6720, device='cuda:6'))\n",
      "([' Cov'], tensor(0.6426, device='cuda:6'))\n",
      "(['yst'], tensor(0.6329, device='cuda:6'))\n",
      "===========================\n",
      "Layer 18, post:\n",
      "([' COVID'], tensor(0.7955, device='cuda:6'))\n",
      "([' virus'], tensor(0.6618, device='cuda:6'))\n",
      "([' Cov'], tensor(0.6578, device='cuda:6'))\n",
      "(['yst'], tensor(0.6509, device='cuda:6'))\n",
      "===========================\n",
      "Layer 19, mid:\n",
      "([' COVID'], tensor(0.7899, device='cuda:6'))\n",
      "(['yst'], tensor(0.6720, device='cuda:6'))\n",
      "([' virus'], tensor(0.6517, device='cuda:6'))\n",
      "([' coronavirus'], tensor(0.6511, device='cuda:6'))\n",
      "===========================\n",
      "Layer 19, post:\n",
      "([' COVID'], tensor(0.6947, device='cuda:6'))\n",
      "(['yst'], tensor(0.6250, device='cuda:6'))\n",
      "(['zone'], tensor(0.5707, device='cuda:6'))\n",
      "([' virus'], tensor(0.5634, device='cuda:6'))\n",
      "===========================\n",
      "Layer 20, mid:\n",
      "([' COVID'], tensor(0.7342, device='cuda:6'))\n",
      "(['yst'], tensor(0.6259, device='cuda:6'))\n",
      "([' coronavirus'], tensor(0.6012, device='cuda:6'))\n",
      "([' Cov'], tensor(0.5869, device='cuda:6'))\n",
      "===========================\n",
      "Layer 20, post:\n",
      "([' COVID'], tensor(0.6561, device='cuda:6'))\n",
      "(['yst'], tensor(0.5995, device='cuda:6'))\n",
      "(['zone'], tensor(0.5822, device='cuda:6'))\n",
      "([' coronavirus'], tensor(0.5752, device='cuda:6'))\n",
      "===========================\n",
      "Layer 21, mid:\n",
      "([' COVID'], tensor(0.7015, device='cuda:6'))\n",
      "([' coronavirus'], tensor(0.6105, device='cuda:6'))\n",
      "(['yst'], tensor(0.5933, device='cuda:6'))\n",
      "(['zone'], tensor(0.5895, device='cuda:6'))\n",
      "===========================\n",
      "Layer 21, post:\n",
      "([' COVID'], tensor(0.6500, device='cuda:6'))\n",
      "(['yst'], tensor(0.6031, device='cuda:6'))\n",
      "(['zone'], tensor(0.5806, device='cuda:6'))\n",
      "(['xygen'], tensor(0.5629, device='cuda:6'))\n",
      "===========================\n",
      "Layer 22, mid:\n",
      "([' COVID'], tensor(0.7086, device='cuda:6'))\n",
      "([' coronavirus'], tensor(0.6125, device='cuda:6'))\n",
      "(['yst'], tensor(0.6019, device='cuda:6'))\n",
      "(['zone'], tensor(0.5866, device='cuda:6'))\n",
      "===========================\n",
      "Layer 22, post:\n",
      "([' COVID'], tensor(0.8053, device='cuda:6'))\n",
      "([' virus'], tensor(0.7272, device='cuda:6'))\n",
      "([' coronavirus'], tensor(0.7030, device='cuda:6'))\n",
      "([' Cov'], tensor(0.6868, device='cuda:6'))\n",
      "===========================\n",
      "Layer 23, mid:\n",
      "([' COVID'], tensor(0.8847, device='cuda:6'))\n",
      "([' virus'], tensor(0.7852, device='cuda:6'))\n",
      "([' coronavirus'], tensor(0.7724, device='cuda:6'))\n",
      "([' Cov'], tensor(0.7438, device='cuda:6'))\n",
      "===========================\n",
      "Layer 23, post:\n",
      "([' COVID'], tensor(0.7733, device='cuda:6'))\n",
      "([' virus'], tensor(0.6929, device='cuda:6'))\n",
      "([' coronavirus'], tensor(0.6906, device='cuda:6'))\n",
      "([' Cov'], tensor(0.6373, device='cuda:6'))\n",
      "===========================\n",
      "Layer 24, mid:\n",
      "([' COVID'], tensor(0.8294, device='cuda:6'))\n",
      "([' coronavirus'], tensor(0.7238, device='cuda:6'))\n",
      "([' virus'], tensor(0.6895, device='cuda:6'))\n",
      "([' Cov'], tensor(0.6866, device='cuda:6'))\n",
      "===========================\n",
      "Layer 24, post:\n",
      "([' COVID'], tensor(0.7282, device='cuda:6'))\n",
      "([' virus'], tensor(0.7115, device='cuda:6'))\n",
      "([' Cov'], tensor(0.6878, device='cuda:6'))\n",
      "([' coronavirus'], tensor(0.6705, device='cuda:6'))\n",
      "===========================\n",
      "Layer 25, mid:\n",
      "([' Christmas'], tensor(1.0315, device='cuda:6'))\n",
      "([' winter'], tensor(0.7812, device='cuda:6'))\n",
      "([' COVID'], tensor(0.7426, device='cuda:6'))\n",
      "([' Cov'], tensor(0.6984, device='cuda:6'))\n",
      "===========================\n",
      "Layer 25, post:\n",
      "([' Christmas'], tensor(0.8849, device='cuda:6'))\n",
      "([' COVID'], tensor(0.7236, device='cuda:6'))\n",
      "([' Cov'], tensor(0.7039, device='cuda:6'))\n",
      "(['zone'], tensor(0.6824, device='cuda:6'))\n",
      "===========================\n",
      "Layer 26, mid:\n",
      "([' Christmas'], tensor(0.9251, device='cuda:6'))\n",
      "([' COVID'], tensor(0.8307, device='cuda:6'))\n",
      "([' Cov'], tensor(0.7684, device='cuda:6'))\n",
      "([' coronavirus'], tensor(0.7471, device='cuda:6'))\n",
      "===========================\n",
      "Layer 26, post:\n",
      "([' Christmas'], tensor(0.8168, device='cuda:6'))\n",
      "([' COVID'], tensor(0.7416, device='cuda:6'))\n",
      "(['zone'], tensor(0.7384, device='cuda:6'))\n",
      "(['xygen'], tensor(0.7311, device='cuda:6'))\n",
      "===========================\n",
      "Layer 27, mid:\n",
      "([' Christmas'], tensor(0.8687, device='cuda:6'))\n",
      "([' COVID'], tensor(0.7853, device='cuda:6'))\n",
      "([' Cov'], tensor(0.7589, device='cuda:6'))\n",
      "([' coronavirus'], tensor(0.7405, device='cuda:6'))\n",
      "===========================\n",
      "Layer 27, post:\n",
      "([' COVID'], tensor(0.7874, device='cuda:6'))\n",
      "(['yster'], tensor(0.7553, device='cuda:6'))\n",
      "(['xygen'], tensor(0.7518, device='cuda:6'))\n",
      "(['zone'], tensor(0.7373, device='cuda:6'))\n",
      "===========================\n",
      "Layer 28, mid:\n",
      "(['yster'], tensor(0.7633, device='cuda:6'))\n",
      "(['xygen'], tensor(0.7624, device='cuda:6'))\n",
      "([' COVID'], tensor(0.7456, device='cuda:6'))\n",
      "(['asis'], tensor(0.7230, device='cuda:6'))\n",
      "===========================\n",
      "Layer 28, post:\n",
      "([' COVID'], tensor(1.1920, device='cuda:6'))\n",
      "([' Cov'], tensor(1.0926, device='cuda:6'))\n",
      "([' coronavirus'], tensor(0.9585, device='cuda:6'))\n",
      "(['xygen'], tensor(0.9219, device='cuda:6'))\n",
      "===========================\n",
      "Layer 29, mid:\n",
      "([' COVID'], tensor(1.2513, device='cuda:6'))\n",
      "([' Cov'], tensor(1.1395, device='cuda:6'))\n",
      "([' coronavirus'], tensor(1.0510, device='cuda:6'))\n",
      "([' pandemic'], tensor(0.9720, device='cuda:6'))\n",
      "===========================\n",
      "Layer 29, post:\n",
      "(['mic'], tensor(1.2195, device='cuda:6'))\n",
      "(['-'], tensor(1.1972, device='cuda:6'))\n",
      "(['.'], tensor(1.0594, device='cuda:6'))\n",
      "(['yster'], tensor(0.9831, device='cuda:6'))\n",
      "===========================\n",
      "Layer 30, mid:\n",
      "(['mic'], tensor(1.2065, device='cuda:6'))\n",
      "(['yster'], tensor(1.0270, device='cuda:6'))\n",
      "(['xygen'], tensor(1.0268, device='cuda:6'))\n",
      "(['culus'], tensor(0.9159, device='cuda:6'))\n",
      "===========================\n",
      "Layer 30, post:\n",
      "(['-'], tensor(1.5444, device='cuda:6'))\n",
      "(['mic'], tensor(1.5315, device='cuda:6'))\n",
      "(['.'], tensor(1.4397, device='cuda:6'))\n",
      "(['2'], tensor(1.2832, device='cuda:6'))\n",
      "===========================\n",
      "Layer 31, mid:\n",
      "(['mic'], tensor(1.6321, device='cuda:6'))\n",
      "(['-'], tensor(1.5755, device='cuda:6'))\n",
      "(['.'], tensor(1.5584, device='cuda:6'))\n",
      "(['2'], tensor(1.3108, device='cuda:6'))\n",
      "===========================\n",
      "Layer 31, post:\n",
      "(['mic'], tensor(4.8025, device='cuda:6'))\n",
      "(['MI'], tensor(2.6920, device='cuda:6'))\n",
      "(['mi'], tensor(2.6101, device='cuda:6'))\n",
      "([' mic'], tensor(2.6015, device='cuda:6'))\n"
     ]
    }
   ],
   "source": [
    "for layer in range(32):\n",
    "    for sublayer in ['mid', 'post']:\n",
    "        print('===========================')\n",
    "        print(f'Layer {layer}, {sublayer}:')\n",
    "        top_token_vi = torch.topk(cache[f'blocks.{layer}.hook_resid_{sublayer}'][0,25]@model.W_U, k=4)\n",
    "        for j in range(4):\n",
    "            print((model.to_str_tokens(top_token_vi.indices[j]), top_token_vi.values[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cfd1f67d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0, mid: -0.009818505495786667\n",
      "Layer 0, post: 0.1756778061389923\n",
      "Layer 1, mid: 0.1873852014541626\n",
      "Layer 1, post: 0.16365423798561096\n",
      "Layer 2, mid: 0.18060725927352905\n",
      "Layer 2, post: 0.17816656827926636\n",
      "Layer 3, mid: 0.16314618289470673\n",
      "Layer 3, post: 0.19512557983398438\n",
      "Layer 4, mid: 0.18644800782203674\n",
      "Layer 4, post: 0.20833870768547058\n",
      "Layer 5, mid: 0.16482438147068024\n",
      "Layer 5, post: 0.15313085913658142\n",
      "Layer 6, mid: 0.14475101232528687\n",
      "Layer 6, post: 0.22487929463386536\n",
      "Layer 7, mid: 0.22021272778511047\n",
      "Layer 7, post: 0.2116979956626892\n",
      "Layer 8, mid: 0.19317162036895752\n",
      "Layer 8, post: 0.2249262034893036\n",
      "Layer 9, mid: 0.2260773777961731\n",
      "Layer 9, post: 0.187677800655365\n",
      "Layer 10, mid: 0.1936216801404953\n",
      "Layer 10, post: 0.2052566558122635\n",
      "Layer 11, mid: 0.22408485412597656\n",
      "Layer 11, post: 0.19123020768165588\n",
      "Layer 12, mid: 0.21115386486053467\n",
      "Layer 12, post: 0.23132723569869995\n",
      "Layer 13, mid: 0.2442898154258728\n",
      "Layer 13, post: 0.25902628898620605\n",
      "Layer 14, mid: 0.27178335189819336\n",
      "Layer 14, post: 0.27256208658218384\n",
      "Layer 15, mid: 0.2834193706512451\n",
      "Layer 15, post: 0.28171712160110474\n",
      "Layer 16, mid: 0.29786670207977295\n",
      "Layer 16, post: 0.32215315103530884\n",
      "Layer 17, mid: 0.3280490040779114\n",
      "Layer 17, post: 0.331258624792099\n",
      "Layer 18, mid: 0.35089704394340515\n",
      "Layer 18, post: 0.3472024202346802\n",
      "Layer 19, mid: 0.3690873384475708\n",
      "Layer 19, post: 0.3712890148162842\n",
      "Layer 20, mid: 0.3847208619117737\n",
      "Layer 20, post: 0.4008021652698517\n",
      "Layer 21, mid: 0.4051680266857147\n",
      "Layer 21, post: 0.4263611137866974\n",
      "Layer 22, mid: 0.42865175008773804\n",
      "Layer 22, post: 0.42717283964157104\n",
      "Layer 23, mid: 0.431043803691864\n",
      "Layer 23, post: 0.44019821286201477\n",
      "Layer 24, mid: 0.44355693459510803\n",
      "Layer 24, post: 0.4863126277923584\n",
      "Layer 25, mid: 0.48850756883621216\n",
      "Layer 25, post: 0.5271747708320618\n",
      "Layer 26, mid: 0.5428463220596313\n",
      "Layer 26, post: 0.5952954888343811\n",
      "Layer 27, mid: 0.6060255169868469\n",
      "Layer 27, post: 0.639245331287384\n",
      "Layer 28, mid: 0.6510517597198486\n",
      "Layer 28, post: 0.8819511532783508\n",
      "Layer 29, mid: 0.8610501885414124\n",
      "Layer 29, post: 1.2195000648498535\n",
      "Layer 30, mid: 1.2065311670303345\n",
      "Layer 30, post: 1.5314865112304688\n",
      "Layer 31, mid: 1.6320769786834717\n",
      "Layer 31, post: 4.80251932144165\n"
     ]
    }
   ],
   "source": [
    "for layer in range(32):\n",
    "    for sublayer in ['mid', 'post']:\n",
    "        print(f'Layer {layer}, {sublayer}: {cache[f'blocks.{layer}.hook_resid_{sublayer}'][0,25]@mic}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2a2d96",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "io2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
